{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e93009",
   "metadata": {},
   "source": [
    "<div class=\"title\" style=\"text-align:center; padding:15px; color: #286fee\">\n",
    "    <h1 style='font-size: 2.8em; letter-spacing:2px;'>Amélioration des performances d'une IA</h1>  \n",
    "</div>   \n",
    "<hr>\n",
    "\n",
    "####  [I - Choix des algorithmes](#1)\n",
    "#### [II - Transformation des données](#2)\n",
    "#### [III - Augmentation des données](#3)\n",
    "#### [IV - Recherche et sélection des meilleures features ](#4)  \n",
    "#### [V - Hyperparamétrage ](#5)  \n",
    "#### [VI - Hyperparamétrage ](#6)  \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "<br>     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8f2f5",
   "metadata": {},
   "source": [
    "<h4>Imports et chargements des données</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5db60713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "import xgboost as xgb\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "#Deep Learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eaedc178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>feature22</th>\n",
       "      <th>feature23</th>\n",
       "      <th>feature24</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>feature35</th>\n",
       "      <th>feature36</th>\n",
       "      <th>feature37</th>\n",
       "      <th>feature38</th>\n",
       "      <th>feature39</th>\n",
       "      <th>feature40</th>\n",
       "      <th>feature41</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>feature51</th>\n",
       "      <th>feature52</th>\n",
       "      <th>feature53</th>\n",
       "      <th>feature54</th>\n",
       "      <th>feature55</th>\n",
       "      <th>feature56</th>\n",
       "      <th>feature57</th>\n",
       "      <th>feature58</th>\n",
       "      <th>feature59</th>\n",
       "      <th>feature60</th>\n",
       "      <th>feature61</th>\n",
       "      <th>feature62</th>\n",
       "      <th>feature63</th>\n",
       "      <th>feature64</th>\n",
       "      <th>feature65</th>\n",
       "      <th>feature66</th>\n",
       "      <th>feature67</th>\n",
       "      <th>feature68</th>\n",
       "      <th>feature69</th>\n",
       "      <th>feature70</th>\n",
       "      <th>feature71</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.027537</td>\n",
       "      <td>0.030757</td>\n",
       "      <td>-0.234750</td>\n",
       "      <td>1.400160</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>2.534833</td>\n",
       "      <td>1.965961</td>\n",
       "      <td>4.468279</td>\n",
       "      <td>8.480426</td>\n",
       "      <td>1.781501</td>\n",
       "      <td>4.295799</td>\n",
       "      <td>8.292971</td>\n",
       "      <td>1.275652</td>\n",
       "      <td>3.594810</td>\n",
       "      <td>7.406123</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>-0.051207</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>27.854098</td>\n",
       "      <td>0.146360</td>\n",
       "      <td>190.312557</td>\n",
       "      <td>218.904421</td>\n",
       "      <td>248.848127</td>\n",
       "      <td>0.989258</td>\n",
       "      <td>4.254340</td>\n",
       "      <td>28.803362</td>\n",
       "      <td>16.002388</td>\n",
       "      <td>326.829977</td>\n",
       "      <td>0.059505</td>\n",
       "      <td>0.189759</td>\n",
       "      <td>1.455967</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.053382</td>\n",
       "      <td>0.612735</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.312147</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.990703</td>\n",
       "      <td>0.994104</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>1290.224519</td>\n",
       "      <td>57.195645</td>\n",
       "      <td>22.558090</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>0.024924</td>\n",
       "      <td>75.744920</td>\n",
       "      <td>1.294533</td>\n",
       "      <td>2.174763</td>\n",
       "      <td>6.876299</td>\n",
       "      <td>74.304180</td>\n",
       "      <td>0.172410</td>\n",
       "      <td>1.739677</td>\n",
       "      <td>5.712770</td>\n",
       "      <td>0.060487</td>\n",
       "      <td>1.389278</td>\n",
       "      <td>5.409682</td>\n",
       "      <td>0.030415</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>4.705684</td>\n",
       "      <td>-0.148203</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.693424</td>\n",
       "      <td>0.878458</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.015646</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.025239</td>\n",
       "      <td>0.027386</td>\n",
       "      <td>-0.320507</td>\n",
       "      <td>1.320474</td>\n",
       "      <td>0.027633</td>\n",
       "      <td>2.436207</td>\n",
       "      <td>2.068875</td>\n",
       "      <td>4.612682</td>\n",
       "      <td>8.624509</td>\n",
       "      <td>1.920656</td>\n",
       "      <td>4.467766</td>\n",
       "      <td>8.464225</td>\n",
       "      <td>1.486343</td>\n",
       "      <td>3.892244</td>\n",
       "      <td>7.378642</td>\n",
       "      <td>0.061915</td>\n",
       "      <td>-0.048430</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>36.747227</td>\n",
       "      <td>0.147407</td>\n",
       "      <td>249.291751</td>\n",
       "      <td>215.347490</td>\n",
       "      <td>308.465418</td>\n",
       "      <td>0.989076</td>\n",
       "      <td>5.452277</td>\n",
       "      <td>37.938055</td>\n",
       "      <td>20.708431</td>\n",
       "      <td>586.709527</td>\n",
       "      <td>0.036323</td>\n",
       "      <td>0.151617</td>\n",
       "      <td>1.284424</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.004915</td>\n",
       "      <td>0.020759</td>\n",
       "      <td>0.276048</td>\n",
       "      <td>0.989116</td>\n",
       "      <td>0.993424</td>\n",
       "      <td>0.996599</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>1300.134391</td>\n",
       "      <td>59.309210</td>\n",
       "      <td>21.921290</td>\n",
       "      <td>0.022144</td>\n",
       "      <td>0.029391</td>\n",
       "      <td>74.102522</td>\n",
       "      <td>1.079594</td>\n",
       "      <td>1.760724</td>\n",
       "      <td>5.882591</td>\n",
       "      <td>63.522091</td>\n",
       "      <td>0.159575</td>\n",
       "      <td>1.870006</td>\n",
       "      <td>5.820697</td>\n",
       "      <td>0.055839</td>\n",
       "      <td>1.517650</td>\n",
       "      <td>5.438242</td>\n",
       "      <td>0.028079</td>\n",
       "      <td>0.997385</td>\n",
       "      <td>4.261073</td>\n",
       "      <td>-0.262911</td>\n",
       "      <td>0.415873</td>\n",
       "      <td>0.663492</td>\n",
       "      <td>0.825170</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.027186</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>-0.098202</td>\n",
       "      <td>1.355550</td>\n",
       "      <td>0.032739</td>\n",
       "      <td>2.425745</td>\n",
       "      <td>2.086889</td>\n",
       "      <td>4.597632</td>\n",
       "      <td>8.612423</td>\n",
       "      <td>1.934987</td>\n",
       "      <td>4.448645</td>\n",
       "      <td>8.448371</td>\n",
       "      <td>1.425325</td>\n",
       "      <td>3.870549</td>\n",
       "      <td>7.521600</td>\n",
       "      <td>0.070706</td>\n",
       "      <td>-0.061246</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>26.802565</td>\n",
       "      <td>0.132869</td>\n",
       "      <td>201.721197</td>\n",
       "      <td>207.109831</td>\n",
       "      <td>207.094614</td>\n",
       "      <td>0.991250</td>\n",
       "      <td>3.345557</td>\n",
       "      <td>15.705076</td>\n",
       "      <td>16.746902</td>\n",
       "      <td>355.116524</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>0.185464</td>\n",
       "      <td>1.435273</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>0.051414</td>\n",
       "      <td>0.618206</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.315807</td>\n",
       "      <td>0.987075</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.993424</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>1170.482911</td>\n",
       "      <td>56.765382</td>\n",
       "      <td>20.619661</td>\n",
       "      <td>0.016399</td>\n",
       "      <td>0.025565</td>\n",
       "      <td>75.848683</td>\n",
       "      <td>1.252494</td>\n",
       "      <td>2.055724</td>\n",
       "      <td>6.221005</td>\n",
       "      <td>62.019871</td>\n",
       "      <td>0.181033</td>\n",
       "      <td>1.915078</td>\n",
       "      <td>5.895178</td>\n",
       "      <td>0.063161</td>\n",
       "      <td>1.534464</td>\n",
       "      <td>5.526666</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>1.040474</td>\n",
       "      <td>4.731524</td>\n",
       "      <td>-0.113639</td>\n",
       "      <td>0.387528</td>\n",
       "      <td>0.660544</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.025250</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>-0.340509</td>\n",
       "      <td>1.325152</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>2.477160</td>\n",
       "      <td>2.071575</td>\n",
       "      <td>4.599358</td>\n",
       "      <td>8.617491</td>\n",
       "      <td>1.916927</td>\n",
       "      <td>4.445084</td>\n",
       "      <td>8.446998</td>\n",
       "      <td>1.426203</td>\n",
       "      <td>3.849175</td>\n",
       "      <td>7.551974</td>\n",
       "      <td>0.058650</td>\n",
       "      <td>-0.057636</td>\n",
       "      <td>0.009751</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>28.856720</td>\n",
       "      <td>0.135954</td>\n",
       "      <td>212.253706</td>\n",
       "      <td>195.422959</td>\n",
       "      <td>220.589233</td>\n",
       "      <td>0.990931</td>\n",
       "      <td>4.604753</td>\n",
       "      <td>33.354575</td>\n",
       "      <td>18.815555</td>\n",
       "      <td>442.103395</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>0.170565</td>\n",
       "      <td>1.389793</td>\n",
       "      <td>0.012446</td>\n",
       "      <td>0.046772</td>\n",
       "      <td>0.582837</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.023416</td>\n",
       "      <td>0.296795</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.995692</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>1197.176290</td>\n",
       "      <td>60.698259</td>\n",
       "      <td>19.723404</td>\n",
       "      <td>0.020086</td>\n",
       "      <td>0.027138</td>\n",
       "      <td>72.786292</td>\n",
       "      <td>1.093601</td>\n",
       "      <td>1.781056</td>\n",
       "      <td>6.147527</td>\n",
       "      <td>64.350440</td>\n",
       "      <td>0.160550</td>\n",
       "      <td>1.991311</td>\n",
       "      <td>5.954551</td>\n",
       "      <td>0.054570</td>\n",
       "      <td>1.652942</td>\n",
       "      <td>5.630565</td>\n",
       "      <td>0.027412</td>\n",
       "      <td>1.240830</td>\n",
       "      <td>4.821161</td>\n",
       "      <td>-0.144498</td>\n",
       "      <td>0.335374</td>\n",
       "      <td>0.619955</td>\n",
       "      <td>0.822449</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027246</td>\n",
       "      <td>0.031357</td>\n",
       "      <td>0.400539</td>\n",
       "      <td>1.381873</td>\n",
       "      <td>0.019049</td>\n",
       "      <td>2.569998</td>\n",
       "      <td>1.968617</td>\n",
       "      <td>4.462123</td>\n",
       "      <td>8.464940</td>\n",
       "      <td>1.779865</td>\n",
       "      <td>4.283685</td>\n",
       "      <td>8.269638</td>\n",
       "      <td>1.262642</td>\n",
       "      <td>3.720701</td>\n",
       "      <td>7.106563</td>\n",
       "      <td>0.050699</td>\n",
       "      <td>-0.042249</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>28.946050</td>\n",
       "      <td>0.134354</td>\n",
       "      <td>215.446479</td>\n",
       "      <td>192.102369</td>\n",
       "      <td>214.612145</td>\n",
       "      <td>0.990965</td>\n",
       "      <td>3.830764</td>\n",
       "      <td>23.156336</td>\n",
       "      <td>17.447968</td>\n",
       "      <td>388.971240</td>\n",
       "      <td>0.057499</td>\n",
       "      <td>0.175027</td>\n",
       "      <td>1.389017</td>\n",
       "      <td>0.016378</td>\n",
       "      <td>0.048098</td>\n",
       "      <td>0.596266</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>0.304451</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.994331</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>1184.266364</td>\n",
       "      <td>55.615840</td>\n",
       "      <td>21.293688</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>76.719082</td>\n",
       "      <td>1.257169</td>\n",
       "      <td>2.095317</td>\n",
       "      <td>6.032436</td>\n",
       "      <td>58.858904</td>\n",
       "      <td>0.180613</td>\n",
       "      <td>1.886066</td>\n",
       "      <td>5.857256</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>1.469637</td>\n",
       "      <td>5.451075</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.967651</td>\n",
       "      <td>4.598768</td>\n",
       "      <td>-0.110002</td>\n",
       "      <td>0.419955</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.849660</td>\n",
       "      <td>0.018367</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0 -0.027537  0.030757 -0.234750  1.400160 -0.000851  2.534833  1.965961   \n",
       "1 -0.025239  0.027386 -0.320507  1.320474  0.027633  2.436207  2.068875   \n",
       "2 -0.027186  0.025507 -0.098202  1.355550  0.032739  2.425745  2.086889   \n",
       "3 -0.025250  0.027777 -0.340509  1.325152  0.061481  2.477160  2.071575   \n",
       "4 -0.027246  0.031357  0.400539  1.381873  0.019049  2.569998  1.968617   \n",
       "\n",
       "   feature8  feature9  feature10  feature11  feature12  feature13  feature14  \\\n",
       "0  4.468279  8.480426   1.781501   4.295799   8.292971   1.275652   3.594810   \n",
       "1  4.612682  8.624509   1.920656   4.467766   8.464225   1.486343   3.892244   \n",
       "2  4.597632  8.612423   1.934987   4.448645   8.448371   1.425325   3.870549   \n",
       "3  4.599358  8.617491   1.916927   4.445084   8.446998   1.426203   3.849175   \n",
       "4  4.462123  8.464940   1.779865   4.283685   8.269638   1.262642   3.720701   \n",
       "\n",
       "   feature15  feature16  feature17  feature18  feature19  feature20  \\\n",
       "0   7.406123   0.074980  -0.051207   0.009524   0.005782   0.000794   \n",
       "1   7.378642   0.061915  -0.048430   0.008957   0.005329   0.001927   \n",
       "2   7.521600   0.070706  -0.061246   0.010204   0.006803   0.003628   \n",
       "3   7.551974   0.058650  -0.057636   0.009751   0.006122   0.002041   \n",
       "4   7.106563   0.050699  -0.042249   0.009297   0.004195   0.000907   \n",
       "\n",
       "   feature21  feature22   feature23   feature24   feature25  feature26  \\\n",
       "0  27.854098   0.146360  190.312557  218.904421  248.848127   0.989258   \n",
       "1  36.747227   0.147407  249.291751  215.347490  308.465418   0.989076   \n",
       "2  26.802565   0.132869  201.721197  207.109831  207.094614   0.991250   \n",
       "3  28.856720   0.135954  212.253706  195.422959  220.589233   0.990931   \n",
       "4  28.946050   0.134354  215.446479  192.102369  214.612145   0.990965   \n",
       "\n",
       "   feature27  feature28  feature29   feature30  feature31  feature32  \\\n",
       "0   4.254340  28.803362  16.002388  326.829977   0.059505   0.189759   \n",
       "1   5.452277  37.938055  20.708431  586.709527   0.036323   0.151617   \n",
       "2   3.345557  15.705076  16.746902  355.116524   0.066171   0.185464   \n",
       "3   4.604753  33.354575  18.815555  442.103395   0.046622   0.170565   \n",
       "4   3.830764  23.156336  17.447968  388.971240   0.057499   0.175027   \n",
       "\n",
       "   feature33  feature34  feature35  feature36  feature37  feature38  \\\n",
       "0   1.455967   0.017037   0.053382   0.612735   0.008531   0.026745   \n",
       "1   1.284424   0.009820   0.041463   0.541436   0.004915   0.020759   \n",
       "2   1.435273   0.019006   0.051414   0.618206   0.009518   0.025745   \n",
       "3   1.389793   0.012446   0.046772   0.582837   0.006229   0.023416   \n",
       "4   1.389017   0.016378   0.048098   0.596266   0.008202   0.024081   \n",
       "\n",
       "   feature39  feature40  feature41  feature42  feature43  feature44  \\\n",
       "0   0.312147   0.985714   0.990703   0.994104   0.005896   0.004989   \n",
       "1   0.276048   0.989116   0.993424   0.996599   0.005442   0.004535   \n",
       "2   0.315807   0.987075   0.990476   0.993424   0.005669   0.004535   \n",
       "3   0.296795   0.987302   0.991156   0.995692   0.005669   0.005442   \n",
       "4   0.304451   0.987302   0.991156   0.994331   0.004989   0.004535   \n",
       "\n",
       "   feature45    feature46  feature47  feature48  feature49  feature50  \\\n",
       "0   0.004535  1290.224519  57.195645  22.558090   0.015494   0.024924   \n",
       "1   0.003175  1300.134391  59.309210  21.921290   0.022144   0.029391   \n",
       "2   0.004535  1170.482911  56.765382  20.619661   0.016399   0.025565   \n",
       "3   0.004989  1197.176290  60.698259  19.723404   0.020086   0.027138   \n",
       "4   0.005442  1184.266364  55.615840  21.293688   0.015300   0.023625   \n",
       "\n",
       "   feature51  feature52  feature53  feature54  feature55  feature56  \\\n",
       "0  75.744920   1.294533   2.174763   6.876299  74.304180   0.172410   \n",
       "1  74.102522   1.079594   1.760724   5.882591  63.522091   0.159575   \n",
       "2  75.848683   1.252494   2.055724   6.221005  62.019871   0.181033   \n",
       "3  72.786292   1.093601   1.781056   6.147527  64.350440   0.160550   \n",
       "4  76.719082   1.257169   2.095317   6.032436  58.858904   0.180613   \n",
       "\n",
       "   feature57  feature58  feature59  feature60  feature61  feature62  \\\n",
       "0   1.739677   5.712770   0.060487   1.389278   5.409682   0.030415   \n",
       "1   1.870006   5.820697   0.055839   1.517650   5.438242   0.028079   \n",
       "2   1.915078   5.895178   0.063161   1.534464   5.526666   0.031752   \n",
       "3   1.991311   5.954551   0.054570   1.652942   5.630565   0.027412   \n",
       "4   1.886066   5.857256   0.063158   1.469637   5.451075   0.031752   \n",
       "\n",
       "   feature63  feature64  feature65  feature66  feature67  feature68  \\\n",
       "0   0.998692   4.705684  -0.148203   0.399546   0.693424   0.878458   \n",
       "1   0.997385   4.261073  -0.262911   0.415873   0.663492   0.825170   \n",
       "2   1.040474   4.731524  -0.113639   0.387528   0.660544   0.826531   \n",
       "3   1.240830   4.821161  -0.144498   0.335374   0.619955   0.822449   \n",
       "4   0.967651   4.598768  -0.110002   0.419955   0.677778   0.849660   \n",
       "\n",
       "   feature69  feature70  feature71 label  \n",
       "0   0.019728   0.015646   0.007029   car  \n",
       "1   0.016780   0.010884   0.008617   car  \n",
       "2   0.020181   0.015193   0.007029   car  \n",
       "3   0.015420   0.014739   0.007937   car  \n",
       "4   0.018367   0.011565   0.007029   car  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings \n",
    "import plotly.express as px\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "file = r'../Data/data'\n",
    "df = pd.read_pickle(file)\n",
    "df_results = pd.DataFrame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c46954",
   "metadata": {},
   "source": [
    "**Vérification / Elimination des données incomplètes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e594d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 colonnes ont été supprimés car les valeurs étaient aberrantes\n"
     ]
    }
   ],
   "source": [
    "tmp = df.shape[1]\n",
    "df.dropna(axis='columns', inplace=True)\n",
    "print(\"{} colonnes ont été supprimés car les valeurs étaient aberrantes\".format(tmp - df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4264f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross validation and get the accuracy scores for each fold\n",
    "def launch_model(model, print_time=False, n_commas=2):\n",
    "    ts = time.time()\n",
    "    model_name = model.__class__.__name__\n",
    "    try :\n",
    "        model.fit(X_train, y_train)    \n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "        te = time.time()\n",
    "        print(f\" %s - Accuracy: %0.{n_commas}f (+/- %0.{n_commas}f)\" % (model_name, scores.mean(), scores.std() * 2))\n",
    "        if print_time :\n",
    "            print(\"Training time : {}\".format(round(te - ts,2),'s'))\n",
    "        return scores.mean()\n",
    "    except ValueError:\n",
    "        print(f\"{model_name} - Valeurs d'entrée non conformes\")\n",
    "        return 0\n",
    "    \n",
    "#Neuronal network\n",
    "def launch_NN(): \n",
    "    ts = time.time()\n",
    "    # Define the model\n",
    "    model = Sequential([\n",
    "        # First layer with 20 neurons, relu activation and input shape\n",
    "        Dense(16, activation='relu', input_dim = X_train.shape[1]),\n",
    "        Dense(16,activation='relu'),\n",
    "        # Output layer for 2-class classification\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = EarlyStopping(\n",
    "    min_delta=0.001,\n",
    "    patience=10,# how many epochs to wait before stopping\n",
    "    restore_best_weights=True,    \n",
    "    )\n",
    "    try : \n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=2,\n",
    "            epochs=100,\n",
    "            validation_split=0.3,\n",
    "            callbacks=[early_stopping] ,\n",
    "            verbose = 0\n",
    "        )\n",
    "        #Prédictions avec le set de test\n",
    "        predictions = model.predict(X_test)    \n",
    "        # Evaluate the model\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "        te = time.time()\n",
    "        print('Réseau Neuronel - Test loss:', test_loss, ' Test accuracy:', test_acc, ' Training time :', round(te - ts,2),'s' )\n",
    "        return test_acc\n",
    "    except :\n",
    "        print('Valeurs d\\'entrée non conformes')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2666aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# répartition des features / labels dans les sets de test et de training\n",
    "X = df.select_dtypes(include=['int', 'float'])\n",
    "y = df[\"label\"]\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "target1 = unique[0]\n",
    "target2 = unique[1]\n",
    "# transformation des labels car/truck en 0 et 1\n",
    "y.replace(to_replace=target1, value=0, inplace=True)\n",
    "y.replace(to_replace=target2, value=1, inplace=True)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b25cb",
   "metadata": {},
   "source": [
    " <a id=\"1\"></a>\n",
    " <div>\n",
    "    <h2 style=\"font-size:1.8em; color: #286fee;text-decoration:underline; letter-spacing:1px\">I - Choix des algorithmes </h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5e6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    AdaBoostClassifier(),\n",
    "    BernoulliNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreeClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    GaussianNB(),\n",
    "    GradientBoostingClassifier(),\n",
    "    HistGradientBoostingClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    LabelPropagation(),\n",
    "    LabelSpreading(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    LinearSVC(),\n",
    "    LogisticRegression(),\n",
    "    MLPClassifier(),\n",
    "    MultinomialNB(),\n",
    "    NearestCentroid(), \n",
    "    NuSVC(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    RandomForestClassifier(),\n",
    "    RidgeClassifier(),\n",
    "    SGDClassifier(),\n",
    "    SVC(),\n",
    "    xgb.XGBClassifier(objective='binary:logistic'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aceda1e",
   "metadata": {},
   "source": [
    "**Machine Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81663c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AdaBoostClassifier - Accuracy: 0.77 (+/- 0.04)\n",
      " BernoulliNB - Accuracy: 0.56 (+/- 0.05)\n",
      " DecisionTreeClassifier - Accuracy: 0.78 (+/- 0.06)\n",
      " ExtraTreeClassifier - Accuracy: 0.76 (+/- 0.05)\n",
      " ExtraTreesClassifier - Accuracy: 0.89 (+/- 0.02)\n",
      " GaussianNB - Accuracy: 0.64 (+/- 0.02)\n",
      " GradientBoostingClassifier - Accuracy: 0.85 (+/- 0.03)\n",
      " HistGradientBoostingClassifier - Accuracy: 0.90 (+/- 0.03)\n",
      " KNeighborsClassifier - Accuracy: 0.79 (+/- 0.04)\n",
      " LabelPropagation - Accuracy: 0.50 (+/- 0.00)\n",
      " LabelSpreading - Accuracy: 0.50 (+/- 0.00)\n",
      " LinearDiscriminantAnalysis - Accuracy: 0.78 (+/- 0.03)\n",
      " LinearSVC - Accuracy: 0.54 (+/- 0.05)\n",
      " LogisticRegression - Accuracy: 0.66 (+/- 0.06)\n",
      " MLPClassifier - Accuracy: 0.68 (+/- 0.10)\n",
      "MultinomialNB - Valeurs d'entrée non conformes\n",
      " NearestCentroid - Accuracy: 0.53 (+/- 0.13)\n",
      " NuSVC - Accuracy: 0.77 (+/- 0.08)\n",
      " QuadraticDiscriminantAnalysis - Accuracy: 0.81 (+/- 0.06)\n",
      " RandomForestClassifier - Accuracy: 0.88 (+/- 0.04)\n",
      " RidgeClassifier - Accuracy: 0.74 (+/- 0.07)\n",
      " SGDClassifier - Accuracy: 0.50 (+/- 0.02)\n",
      " SVC - Accuracy: 0.65 (+/- 0.07)\n",
      " XGBClassifier - Accuracy: 0.89 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=42)\n",
    "accuracy_scores = []\n",
    "for model in model_names :     \n",
    "    sc = launch_model(model)\n",
    "    accuracy_scores.append(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07790b1c",
   "metadata": {},
   "source": [
    "**Deep Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ccb9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.6725\n",
      "Réseau Neuronel - Test loss: 0.9550289511680603  Test accuracy: 0.6725440621376038  Training time : 23.87 s\n"
     ]
    }
   ],
   "source": [
    "sc_nn = launch_NN()\n",
    "accuracy_scores.append(sc_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84720de",
   "metadata": {},
   "source": [
    "**Résultats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dcebdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.897236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.893457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.885261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.884005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.853102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.805831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.791318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.778678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.776813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.774926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>0.767982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.756636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.742150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.683535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neuronal Network</td>\n",
       "      <td>0.672544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.658278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.653870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.643136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.558614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.539109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.525280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.503155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.498738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.498738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_name   default\n",
       "7   HistGradientBoostingClassifier  0.897236\n",
       "4             ExtraTreesClassifier  0.893457\n",
       "23                   XGBClassifier  0.885261\n",
       "19          RandomForestClassifier  0.884005\n",
       "6       GradientBoostingClassifier  0.853102\n",
       "18   QuadraticDiscriminantAnalysis  0.805831\n",
       "8             KNeighborsClassifier  0.791318\n",
       "2           DecisionTreeClassifier  0.778678\n",
       "11      LinearDiscriminantAnalysis  0.776813\n",
       "0               AdaBoostClassifier  0.774926\n",
       "17                           NuSVC  0.767982\n",
       "3              ExtraTreeClassifier  0.756636\n",
       "20                 RidgeClassifier  0.742150\n",
       "14                   MLPClassifier  0.683535\n",
       "24                Neuronal Network  0.672544\n",
       "13              LogisticRegression  0.658278\n",
       "22                             SVC  0.653870\n",
       "5                       GaussianNB  0.643136\n",
       "1                      BernoulliNB  0.558614\n",
       "12                       LinearSVC  0.539109\n",
       "16                 NearestCentroid  0.525280\n",
       "21                   SGDClassifier  0.503155\n",
       "10                  LabelSpreading  0.498738\n",
       "9                 LabelPropagation  0.498738\n",
       "15                   MultinomialNB  0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_names = [model.__class__.__name__ for model in model_names]\n",
    "row_names.append(\"Neuronal Network\")\n",
    "df_results['model_name'] = row_names\n",
    "df_results['default'] = accuracy_scores\n",
    "df_results.sort_values(\"default\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf165b68",
   "metadata": {},
   "source": [
    " <a id=\"2\"></a>\n",
    " <div>\n",
    "    <h2 style=\"font-size:1.8em; color: #286fee;text-decoration:underline; letter-spacing:1px\">II - Transformation des données </h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0437ef81",
   "metadata": {},
   "source": [
    "**Normalisation**  \n",
    "Cette méthode met les données à l'échelle dans une plage spécifique, généralement entre 0 et 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfa05a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87358825, 0.14563782, 0.30248822, ..., 0.08202834, 0.09821429,\n",
       "        0.0483871 ],\n",
       "       [0.83621317, 0.17146044, 0.06355066, ..., 0.08128262, 0.08928571,\n",
       "        0.0483871 ],\n",
       "       [0.80492333, 0.17885522, 0.54117507, ..., 0.06040268, 0.03571429,\n",
       "        0.02419355],\n",
       "       ...,\n",
       "       [0.83411495, 0.09880547, 0.32893436, ..., 0.07904549, 0.13169643,\n",
       "        0.10080645],\n",
       "       [0.86588831, 0.13897008, 0.51493483, ..., 0.09395973, 0.05357143,\n",
       "        0.03225806],\n",
       "       [0.82849561, 0.15488697, 0.36642987, ..., 0.12378822, 0.06696429,\n",
       "        0.07258065]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a18293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AdaBoostClassifier - Accuracy: 0.77 (+/- 0.04)\n",
      " BernoulliNB - Accuracy: 0.51 (+/- 0.02)\n",
      " DecisionTreeClassifier - Accuracy: 0.78 (+/- 0.06)\n",
      " ExtraTreeClassifier - Accuracy: 0.75 (+/- 0.05)\n",
      " ExtraTreesClassifier - Accuracy: 0.89 (+/- 0.04)\n",
      " GaussianNB - Accuracy: 0.66 (+/- 0.03)\n",
      " GradientBoostingClassifier - Accuracy: 0.85 (+/- 0.03)\n",
      " HistGradientBoostingClassifier - Accuracy: 0.90 (+/- 0.03)\n",
      " KNeighborsClassifier - Accuracy: 0.83 (+/- 0.03)\n",
      " LabelPropagation - Accuracy: 0.83 (+/- 0.04)\n",
      " LabelSpreading - Accuracy: 0.83 (+/- 0.05)\n",
      " LinearDiscriminantAnalysis - Accuracy: 0.78 (+/- 0.03)\n",
      " LinearSVC - Accuracy: 0.73 (+/- 0.07)\n",
      " LogisticRegression - Accuracy: 0.69 (+/- 0.10)\n",
      " MLPClassifier - Accuracy: 0.77 (+/- 0.06)\n",
      " MultinomialNB - Accuracy: 0.59 (+/- 0.08)\n",
      " NearestCentroid - Accuracy: 0.59 (+/- 0.09)\n",
      " NuSVC - Accuracy: 0.82 (+/- 0.07)\n",
      " QuadraticDiscriminantAnalysis - Accuracy: 0.81 (+/- 0.06)\n",
      " RandomForestClassifier - Accuracy: 0.89 (+/- 0.03)\n",
      " RidgeClassifier - Accuracy: 0.72 (+/- 0.09)\n",
      " SGDClassifier - Accuracy: 0.70 (+/- 0.09)\n",
      " SVC - Accuracy: 0.69 (+/- 0.07)\n",
      " XGBClassifier - Accuracy: 0.89 (+/- 0.03)\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7884\n",
      "Réseau Neuronel - Test loss: 0.43040794134140015  Test accuracy: 0.7884131073951721  Training time : 61.07 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>default</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.897236</td>\n",
       "      <td>0.897236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.893457</td>\n",
       "      <td>0.894725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.884005</td>\n",
       "      <td>0.885265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.885261</td>\n",
       "      <td>0.885261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.853102</td>\n",
       "      <td>0.852473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.834194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.791318</td>\n",
       "      <td>0.832296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.831046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>0.767982</td>\n",
       "      <td>0.817818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.805831</td>\n",
       "      <td>0.805831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neuronal Network</td>\n",
       "      <td>0.672544</td>\n",
       "      <td>0.788413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.776813</td>\n",
       "      <td>0.776813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.778678</td>\n",
       "      <td>0.776791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.683535</td>\n",
       "      <td>0.774307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.774926</td>\n",
       "      <td>0.774295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.756636</td>\n",
       "      <td>0.753483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.539109</td>\n",
       "      <td>0.728276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.742150</td>\n",
       "      <td>0.720070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.503155</td>\n",
       "      <td>0.703660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.658278</td>\n",
       "      <td>0.689820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.653870</td>\n",
       "      <td>0.687925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.643136</td>\n",
       "      <td>0.657643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.525280</td>\n",
       "      <td>0.592651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.558614</td>\n",
       "      <td>0.513874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_name   default  normalized\n",
       "7   HistGradientBoostingClassifier  0.897236    0.897236\n",
       "4             ExtraTreesClassifier  0.893457    0.894725\n",
       "19          RandomForestClassifier  0.884005    0.885265\n",
       "23                   XGBClassifier  0.885261    0.885261\n",
       "6       GradientBoostingClassifier  0.853102    0.852473\n",
       "9                 LabelPropagation  0.498738    0.834194\n",
       "8             KNeighborsClassifier  0.791318    0.832296\n",
       "10                  LabelSpreading  0.498738    0.831046\n",
       "17                           NuSVC  0.767982    0.817818\n",
       "18   QuadraticDiscriminantAnalysis  0.805831    0.805831\n",
       "24                Neuronal Network  0.672544    0.788413\n",
       "11      LinearDiscriminantAnalysis  0.776813    0.776813\n",
       "2           DecisionTreeClassifier  0.778678    0.776791\n",
       "14                   MLPClassifier  0.683535    0.774307\n",
       "0               AdaBoostClassifier  0.774926    0.774295\n",
       "3              ExtraTreeClassifier  0.756636    0.753483\n",
       "12                       LinearSVC  0.539109    0.728276\n",
       "20                 RidgeClassifier  0.742150    0.720070\n",
       "21                   SGDClassifier  0.503155    0.703660\n",
       "13              LogisticRegression  0.658278    0.689820\n",
       "22                             SVC  0.653870    0.687925\n",
       "5                       GaussianNB  0.643136    0.657643\n",
       "16                 NearestCentroid  0.525280    0.592651\n",
       "15                   MultinomialNB  0.000000    0.592016\n",
       "1                      BernoulliNB  0.558614    0.513874"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_scores = []\n",
    "for model in model_names :     \n",
    "    sc = launch_model(model)\n",
    "    normalized_scores.append(sc)\n",
    "sc_nn = launch_NN()\n",
    "normalized_scores.append(sc_nn)\n",
    "df_results['normalized'] = normalized_scores\n",
    "df_results.sort_values('normalized', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a2d19",
   "metadata": {},
   "source": [
    "**Standardisation**  \n",
    "La standardisation est un type de normalisation qui transforme les données pour avoir une moyenne de zéro et un écart type de un."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5d3578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3065729 ,  0.04142703, -0.83446383, ..., -0.33581131,\n",
       "         0.14280319, -0.24803973],\n",
       "       [-0.3451735 ,  0.43527351, -2.48707521, ..., -0.34846285,\n",
       "         0.01944064, -0.24803973],\n",
       "       [-0.89080576,  0.54805871,  0.8164135 , ..., -0.70270598,\n",
       "        -0.72073461, -0.57338167],\n",
       "       ...,\n",
       "       [-0.38176241, -0.67285963, -0.65154918, ..., -0.38641747,\n",
       "         0.60541272,  0.45686781],\n",
       "       [ 0.17230137, -0.06026924,  0.63492289, ..., -0.13338666,\n",
       "        -0.47400953, -0.46493436],\n",
       "       [-0.47975236,  0.18249495, -0.39221148, ...,  0.37267495,\n",
       "        -0.28896571,  0.07730221]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_standard = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standard, y, test_size = 0.2, stratify=y, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bfe774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AdaBoostClassifier - Accuracy: 0.77 (+/- 0.04)\n",
      " BernoulliNB - Accuracy: 0.56 (+/- 0.09)\n",
      " DecisionTreeClassifier - Accuracy: 0.78 (+/- 0.06)\n",
      " ExtraTreeClassifier - Accuracy: 0.77 (+/- 0.05)\n",
      " ExtraTreesClassifier - Accuracy: 0.89 (+/- 0.03)\n",
      " GaussianNB - Accuracy: 0.66 (+/- 0.03)\n",
      " GradientBoostingClassifier - Accuracy: 0.85 (+/- 0.03)\n",
      " HistGradientBoostingClassifier - Accuracy: 0.90 (+/- 0.03)\n",
      " KNeighborsClassifier - Accuracy: 0.83 (+/- 0.02)\n",
      " LabelPropagation - Accuracy: 0.81 (+/- 0.06)\n",
      " LabelSpreading - Accuracy: 0.81 (+/- 0.06)\n",
      " LinearDiscriminantAnalysis - Accuracy: 0.78 (+/- 0.03)\n",
      " LinearSVC - Accuracy: 0.77 (+/- 0.05)\n",
      " LogisticRegression - Accuracy: 0.75 (+/- 0.06)\n",
      " MLPClassifier - Accuracy: 0.86 (+/- 0.03)\n",
      "MultinomialNB - Valeurs d'entrée non conformes\n",
      " NearestCentroid - Accuracy: 0.60 (+/- 0.06)\n",
      " NuSVC - Accuracy: 0.83 (+/- 0.06)\n",
      " QuadraticDiscriminantAnalysis - Accuracy: 0.81 (+/- 0.06)\n",
      " RandomForestClassifier - Accuracy: 0.88 (+/- 0.02)\n",
      " RidgeClassifier - Accuracy: 0.77 (+/- 0.04)\n",
      " SGDClassifier - Accuracy: 0.70 (+/- 0.07)\n",
      " SVC - Accuracy: 0.77 (+/- 0.06)\n",
      " XGBClassifier - Accuracy: 0.89 (+/- 0.03)\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8363\n",
      "Réseau Neuronel - Test loss: 0.3916858434677124  Test accuracy: 0.8362720608711243  Training time : 24.79 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>default</th>\n",
       "      <th>normalized</th>\n",
       "      <th>standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.897236</td>\n",
       "      <td>0.897236</td>\n",
       "      <td>0.896605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.893457</td>\n",
       "      <td>0.894725</td>\n",
       "      <td>0.887782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.885261</td>\n",
       "      <td>0.885261</td>\n",
       "      <td>0.885261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.884005</td>\n",
       "      <td>0.885265</td>\n",
       "      <td>0.881475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.683535</td>\n",
       "      <td>0.774307</td>\n",
       "      <td>0.864453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.853102</td>\n",
       "      <td>0.852473</td>\n",
       "      <td>0.851215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neuronal Network</td>\n",
       "      <td>0.672544</td>\n",
       "      <td>0.788413</td>\n",
       "      <td>0.836272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.791318</td>\n",
       "      <td>0.832296</td>\n",
       "      <td>0.831030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>0.767982</td>\n",
       "      <td>0.817818</td>\n",
       "      <td>0.829163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.834194</td>\n",
       "      <td>0.812771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.831046</td>\n",
       "      <td>0.812771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.805831</td>\n",
       "      <td>0.805831</td>\n",
       "      <td>0.805831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.778678</td>\n",
       "      <td>0.776791</td>\n",
       "      <td>0.783098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.776813</td>\n",
       "      <td>0.776813</td>\n",
       "      <td>0.776813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.653870</td>\n",
       "      <td>0.687925</td>\n",
       "      <td>0.774305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.774926</td>\n",
       "      <td>0.774295</td>\n",
       "      <td>0.774295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.742150</td>\n",
       "      <td>0.720070</td>\n",
       "      <td>0.769254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.756636</td>\n",
       "      <td>0.753483</td>\n",
       "      <td>0.768617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.539109</td>\n",
       "      <td>0.728276</td>\n",
       "      <td>0.766095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.658278</td>\n",
       "      <td>0.689820</td>\n",
       "      <td>0.749084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.503155</td>\n",
       "      <td>0.703660</td>\n",
       "      <td>0.704301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.643136</td>\n",
       "      <td>0.657643</td>\n",
       "      <td>0.657643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.525280</td>\n",
       "      <td>0.592651</td>\n",
       "      <td>0.600855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.558614</td>\n",
       "      <td>0.513874</td>\n",
       "      <td>0.564270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592016</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_name   default  normalized  standardized\n",
       "7   HistGradientBoostingClassifier  0.897236    0.897236      0.896605\n",
       "4             ExtraTreesClassifier  0.893457    0.894725      0.887782\n",
       "23                   XGBClassifier  0.885261    0.885261      0.885261\n",
       "19          RandomForestClassifier  0.884005    0.885265      0.881475\n",
       "14                   MLPClassifier  0.683535    0.774307      0.864453\n",
       "6       GradientBoostingClassifier  0.853102    0.852473      0.851215\n",
       "24                Neuronal Network  0.672544    0.788413      0.836272\n",
       "8             KNeighborsClassifier  0.791318    0.832296      0.831030\n",
       "17                           NuSVC  0.767982    0.817818      0.829163\n",
       "9                 LabelPropagation  0.498738    0.834194      0.812771\n",
       "10                  LabelSpreading  0.498738    0.831046      0.812771\n",
       "18   QuadraticDiscriminantAnalysis  0.805831    0.805831      0.805831\n",
       "2           DecisionTreeClassifier  0.778678    0.776791      0.783098\n",
       "11      LinearDiscriminantAnalysis  0.776813    0.776813      0.776813\n",
       "22                             SVC  0.653870    0.687925      0.774305\n",
       "0               AdaBoostClassifier  0.774926    0.774295      0.774295\n",
       "20                 RidgeClassifier  0.742150    0.720070      0.769254\n",
       "3              ExtraTreeClassifier  0.756636    0.753483      0.768617\n",
       "12                       LinearSVC  0.539109    0.728276      0.766095\n",
       "13              LogisticRegression  0.658278    0.689820      0.749084\n",
       "21                   SGDClassifier  0.503155    0.703660      0.704301\n",
       "5                       GaussianNB  0.643136    0.657643      0.657643\n",
       "16                 NearestCentroid  0.525280    0.592651      0.600855\n",
       "1                      BernoulliNB  0.558614    0.513874      0.564270\n",
       "15                   MultinomialNB  0.000000    0.592016      0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_results = df_results.drop('standardized', axis=1)\n",
    "standardized_scores = []\n",
    "for model in model_names :     \n",
    "    sc = launch_model(model)\n",
    "    standardized_scores.append(sc)\n",
    "sc_nn = launch_NN()\n",
    "standardized_scores.append(sc_nn)\n",
    "df_results['standardized'] = standardized_scores\n",
    "df_results.sort_values('standardized', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55021e",
   "metadata": {},
   "source": [
    "**Log normalisation**  \n",
    "Cette méthode transforme les données en appliquant la fonction logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7b7671e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>feature22</th>\n",
       "      <th>feature23</th>\n",
       "      <th>feature24</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>feature35</th>\n",
       "      <th>feature36</th>\n",
       "      <th>feature37</th>\n",
       "      <th>feature38</th>\n",
       "      <th>feature39</th>\n",
       "      <th>feature40</th>\n",
       "      <th>feature41</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>feature51</th>\n",
       "      <th>feature52</th>\n",
       "      <th>feature53</th>\n",
       "      <th>feature54</th>\n",
       "      <th>feature55</th>\n",
       "      <th>feature56</th>\n",
       "      <th>feature57</th>\n",
       "      <th>feature58</th>\n",
       "      <th>feature59</th>\n",
       "      <th>feature60</th>\n",
       "      <th>feature61</th>\n",
       "      <th>feature62</th>\n",
       "      <th>feature63</th>\n",
       "      <th>feature64</th>\n",
       "      <th>feature65</th>\n",
       "      <th>feature66</th>\n",
       "      <th>feature67</th>\n",
       "      <th>feature68</th>\n",
       "      <th>feature69</th>\n",
       "      <th>feature70</th>\n",
       "      <th>feature71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>-0.032028</td>\n",
       "      <td>0.034022</td>\n",
       "      <td>0.370835</td>\n",
       "      <td>0.864550</td>\n",
       "      <td>-0.118525</td>\n",
       "      <td>1.264972</td>\n",
       "      <td>1.037867</td>\n",
       "      <td>1.667196</td>\n",
       "      <td>2.231905</td>\n",
       "      <td>0.967313</td>\n",
       "      <td>1.633548</td>\n",
       "      <td>2.212393</td>\n",
       "      <td>0.768427</td>\n",
       "      <td>1.522354</td>\n",
       "      <td>2.110041</td>\n",
       "      <td>0.250438</td>\n",
       "      <td>-0.400312</td>\n",
       "      <td>0.040441</td>\n",
       "      <td>0.012395</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>3.659839</td>\n",
       "      <td>0.240309</td>\n",
       "      <td>4.944186</td>\n",
       "      <td>6.274369</td>\n",
       "      <td>7.086494</td>\n",
       "      <td>0.674185</td>\n",
       "      <td>1.071766</td>\n",
       "      <td>1.661296</td>\n",
       "      <td>3.124062</td>\n",
       "      <td>6.541088</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.247181</td>\n",
       "      <td>1.310267</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.101472</td>\n",
       "      <td>0.927177</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.052588</td>\n",
       "      <td>0.587749</td>\n",
       "      <td>0.684493</td>\n",
       "      <td>0.690650</td>\n",
       "      <td>0.692353</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>7.781603</td>\n",
       "      <td>4.120589</td>\n",
       "      <td>3.701950</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.030081</td>\n",
       "      <td>4.345690</td>\n",
       "      <td>0.751574</td>\n",
       "      <td>1.033199</td>\n",
       "      <td>2.647241</td>\n",
       "      <td>5.802115</td>\n",
       "      <td>0.038913</td>\n",
       "      <td>0.710238</td>\n",
       "      <td>1.792275</td>\n",
       "      <td>0.011068</td>\n",
       "      <td>0.540995</td>\n",
       "      <td>1.740721</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.346385</td>\n",
       "      <td>1.622876</td>\n",
       "      <td>-0.529971</td>\n",
       "      <td>0.474529</td>\n",
       "      <td>0.642570</td>\n",
       "      <td>0.679218</td>\n",
       "      <td>0.049977</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>0.006104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>-0.028646</td>\n",
       "      <td>0.025474</td>\n",
       "      <td>0.241102</td>\n",
       "      <td>0.875787</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>1.107291</td>\n",
       "      <td>1.104043</td>\n",
       "      <td>1.708234</td>\n",
       "      <td>2.255059</td>\n",
       "      <td>1.061015</td>\n",
       "      <td>1.688804</td>\n",
       "      <td>2.242157</td>\n",
       "      <td>0.987298</td>\n",
       "      <td>1.602304</td>\n",
       "      <td>2.161056</td>\n",
       "      <td>0.116854</td>\n",
       "      <td>-0.104198</td>\n",
       "      <td>0.013626</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>3.765178</td>\n",
       "      <td>0.141159</td>\n",
       "      <td>5.631786</td>\n",
       "      <td>5.406202</td>\n",
       "      <td>6.080642</td>\n",
       "      <td>0.687393</td>\n",
       "      <td>1.499706</td>\n",
       "      <td>2.834561</td>\n",
       "      <td>3.366765</td>\n",
       "      <td>6.908809</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>0.139580</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.046226</td>\n",
       "      <td>0.472858</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>0.267950</td>\n",
       "      <td>0.688829</td>\n",
       "      <td>0.691445</td>\n",
       "      <td>0.692580</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>7.198170</td>\n",
       "      <td>4.185365</td>\n",
       "      <td>3.074695</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.027705</td>\n",
       "      <td>4.255801</td>\n",
       "      <td>0.788180</td>\n",
       "      <td>1.080784</td>\n",
       "      <td>1.902870</td>\n",
       "      <td>4.256025</td>\n",
       "      <td>0.133624</td>\n",
       "      <td>1.074274</td>\n",
       "      <td>1.933360</td>\n",
       "      <td>0.049278</td>\n",
       "      <td>0.959709</td>\n",
       "      <td>1.889386</td>\n",
       "      <td>0.025095</td>\n",
       "      <td>0.760833</td>\n",
       "      <td>1.781143</td>\n",
       "      <td>-0.262815</td>\n",
       "      <td>0.296824</td>\n",
       "      <td>0.484915</td>\n",
       "      <td>0.595067</td>\n",
       "      <td>0.024637</td>\n",
       "      <td>0.017087</td>\n",
       "      <td>0.015748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>-0.028829</td>\n",
       "      <td>0.030722</td>\n",
       "      <td>0.558112</td>\n",
       "      <td>0.933043</td>\n",
       "      <td>0.052116</td>\n",
       "      <td>1.316040</td>\n",
       "      <td>1.076122</td>\n",
       "      <td>1.696325</td>\n",
       "      <td>2.248102</td>\n",
       "      <td>1.007588</td>\n",
       "      <td>1.659361</td>\n",
       "      <td>2.225989</td>\n",
       "      <td>0.807709</td>\n",
       "      <td>1.543810</td>\n",
       "      <td>2.113079</td>\n",
       "      <td>0.147325</td>\n",
       "      <td>-0.192890</td>\n",
       "      <td>0.019536</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>3.439345</td>\n",
       "      <td>0.168664</td>\n",
       "      <td>5.107136</td>\n",
       "      <td>5.429961</td>\n",
       "      <td>6.446549</td>\n",
       "      <td>0.684600</td>\n",
       "      <td>1.274247</td>\n",
       "      <td>2.103799</td>\n",
       "      <td>2.928116</td>\n",
       "      <td>6.008690</td>\n",
       "      <td>0.041780</td>\n",
       "      <td>0.203219</td>\n",
       "      <td>1.118452</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>0.068792</td>\n",
       "      <td>0.682258</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.035146</td>\n",
       "      <td>0.405570</td>\n",
       "      <td>0.686207</td>\n",
       "      <td>0.689285</td>\n",
       "      <td>0.691218</td>\n",
       "      <td>0.009029</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>7.390991</td>\n",
       "      <td>4.072976</td>\n",
       "      <td>3.369581</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>0.026906</td>\n",
       "      <td>4.344429</td>\n",
       "      <td>0.827322</td>\n",
       "      <td>1.147865</td>\n",
       "      <td>2.175402</td>\n",
       "      <td>4.700574</td>\n",
       "      <td>0.097515</td>\n",
       "      <td>0.914317</td>\n",
       "      <td>1.864827</td>\n",
       "      <td>0.032889</td>\n",
       "      <td>0.779708</td>\n",
       "      <td>1.813913</td>\n",
       "      <td>0.016642</td>\n",
       "      <td>0.565027</td>\n",
       "      <td>1.673684</td>\n",
       "      <td>-0.307062</td>\n",
       "      <td>0.396963</td>\n",
       "      <td>0.575619</td>\n",
       "      <td>0.647803</td>\n",
       "      <td>0.032570</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.008355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>-0.039039</td>\n",
       "      <td>0.031770</td>\n",
       "      <td>-0.428119</td>\n",
       "      <td>0.840299</td>\n",
       "      <td>-0.233262</td>\n",
       "      <td>1.407018</td>\n",
       "      <td>1.009093</td>\n",
       "      <td>1.652052</td>\n",
       "      <td>2.222776</td>\n",
       "      <td>0.924808</td>\n",
       "      <td>1.605831</td>\n",
       "      <td>2.196560</td>\n",
       "      <td>0.730227</td>\n",
       "      <td>1.472869</td>\n",
       "      <td>2.076597</td>\n",
       "      <td>0.167599</td>\n",
       "      <td>-0.185110</td>\n",
       "      <td>0.036513</td>\n",
       "      <td>0.012730</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>2.978628</td>\n",
       "      <td>0.260340</td>\n",
       "      <td>4.155009</td>\n",
       "      <td>6.433919</td>\n",
       "      <td>6.726297</td>\n",
       "      <td>0.670438</td>\n",
       "      <td>1.003988</td>\n",
       "      <td>1.780174</td>\n",
       "      <td>2.109490</td>\n",
       "      <td>4.421180</td>\n",
       "      <td>0.109141</td>\n",
       "      <td>0.574387</td>\n",
       "      <td>1.365110</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>0.272998</td>\n",
       "      <td>0.877849</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.147494</td>\n",
       "      <td>0.547120</td>\n",
       "      <td>0.649108</td>\n",
       "      <td>0.669514</td>\n",
       "      <td>0.686549</td>\n",
       "      <td>0.037169</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>7.871486</td>\n",
       "      <td>3.853629</td>\n",
       "      <td>4.056370</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>4.470633</td>\n",
       "      <td>0.918773</td>\n",
       "      <td>1.283796</td>\n",
       "      <td>2.942992</td>\n",
       "      <td>6.077320</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>0.390315</td>\n",
       "      <td>1.680479</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.196946</td>\n",
       "      <td>1.627172</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.106031</td>\n",
       "      <td>1.536250</td>\n",
       "      <td>-0.244566</td>\n",
       "      <td>0.600679</td>\n",
       "      <td>0.681056</td>\n",
       "      <td>0.687120</td>\n",
       "      <td>0.037606</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.002039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>-0.039183</td>\n",
       "      <td>0.033302</td>\n",
       "      <td>0.374027</td>\n",
       "      <td>0.856410</td>\n",
       "      <td>0.047072</td>\n",
       "      <td>1.464493</td>\n",
       "      <td>0.992642</td>\n",
       "      <td>1.643530</td>\n",
       "      <td>2.218347</td>\n",
       "      <td>0.895917</td>\n",
       "      <td>1.589784</td>\n",
       "      <td>2.188573</td>\n",
       "      <td>0.669859</td>\n",
       "      <td>1.446585</td>\n",
       "      <td>2.084488</td>\n",
       "      <td>0.233070</td>\n",
       "      <td>-0.165172</td>\n",
       "      <td>0.030813</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>2.668223</td>\n",
       "      <td>0.275654</td>\n",
       "      <td>3.767326</td>\n",
       "      <td>6.591060</td>\n",
       "      <td>6.646252</td>\n",
       "      <td>0.666955</td>\n",
       "      <td>0.973778</td>\n",
       "      <td>1.688577</td>\n",
       "      <td>1.910258</td>\n",
       "      <td>3.921696</td>\n",
       "      <td>0.208552</td>\n",
       "      <td>0.700264</td>\n",
       "      <td>1.467657</td>\n",
       "      <td>0.086885</td>\n",
       "      <td>0.351484</td>\n",
       "      <td>0.952540</td>\n",
       "      <td>0.044846</td>\n",
       "      <td>0.193625</td>\n",
       "      <td>0.598205</td>\n",
       "      <td>0.637548</td>\n",
       "      <td>0.658072</td>\n",
       "      <td>0.677377</td>\n",
       "      <td>0.034325</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>0.026847</td>\n",
       "      <td>7.937489</td>\n",
       "      <td>3.777310</td>\n",
       "      <td>4.198110</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>4.497436</td>\n",
       "      <td>0.943759</td>\n",
       "      <td>1.334856</td>\n",
       "      <td>3.063163</td>\n",
       "      <td>6.275750</td>\n",
       "      <td>0.024897</td>\n",
       "      <td>0.331638</td>\n",
       "      <td>1.651574</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.160074</td>\n",
       "      <td>1.589612</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.084994</td>\n",
       "      <td>1.465978</td>\n",
       "      <td>-0.262432</td>\n",
       "      <td>0.617206</td>\n",
       "      <td>0.683578</td>\n",
       "      <td>0.688488</td>\n",
       "      <td>0.025522</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-0.035565</td>\n",
       "      <td>0.039064</td>\n",
       "      <td>-0.117074</td>\n",
       "      <td>0.871342</td>\n",
       "      <td>0.153608</td>\n",
       "      <td>1.438789</td>\n",
       "      <td>0.986350</td>\n",
       "      <td>1.632967</td>\n",
       "      <td>2.210680</td>\n",
       "      <td>0.905143</td>\n",
       "      <td>1.585216</td>\n",
       "      <td>2.184549</td>\n",
       "      <td>0.703309</td>\n",
       "      <td>1.466739</td>\n",
       "      <td>2.076597</td>\n",
       "      <td>0.088099</td>\n",
       "      <td>-0.065504</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>3.195003</td>\n",
       "      <td>0.163118</td>\n",
       "      <td>4.891328</td>\n",
       "      <td>5.575766</td>\n",
       "      <td>5.665346</td>\n",
       "      <td>0.685257</td>\n",
       "      <td>1.239461</td>\n",
       "      <td>2.327382</td>\n",
       "      <td>2.526754</td>\n",
       "      <td>5.187216</td>\n",
       "      <td>0.085485</td>\n",
       "      <td>0.313682</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.112475</td>\n",
       "      <td>0.529659</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.058061</td>\n",
       "      <td>0.304742</td>\n",
       "      <td>0.677377</td>\n",
       "      <td>0.683692</td>\n",
       "      <td>0.688374</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>7.353950</td>\n",
       "      <td>3.925098</td>\n",
       "      <td>3.479458</td>\n",
       "      <td>0.015751</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>4.411846</td>\n",
       "      <td>0.830766</td>\n",
       "      <td>1.160258</td>\n",
       "      <td>2.391564</td>\n",
       "      <td>4.947398</td>\n",
       "      <td>0.092648</td>\n",
       "      <td>0.844998</td>\n",
       "      <td>1.835887</td>\n",
       "      <td>0.028467</td>\n",
       "      <td>0.669556</td>\n",
       "      <td>1.776921</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.452514</td>\n",
       "      <td>1.629425</td>\n",
       "      <td>-0.125965</td>\n",
       "      <td>0.436718</td>\n",
       "      <td>0.612670</td>\n",
       "      <td>0.664276</td>\n",
       "      <td>0.024195</td>\n",
       "      <td>0.010377</td>\n",
       "      <td>0.004299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>-0.042378</td>\n",
       "      <td>0.037097</td>\n",
       "      <td>0.191929</td>\n",
       "      <td>0.857969</td>\n",
       "      <td>-0.011552</td>\n",
       "      <td>1.415862</td>\n",
       "      <td>0.954682</td>\n",
       "      <td>1.620754</td>\n",
       "      <td>2.205050</td>\n",
       "      <td>0.859478</td>\n",
       "      <td>1.574328</td>\n",
       "      <td>2.179332</td>\n",
       "      <td>0.634716</td>\n",
       "      <td>1.461436</td>\n",
       "      <td>2.064042</td>\n",
       "      <td>0.364807</td>\n",
       "      <td>-0.491284</td>\n",
       "      <td>0.072057</td>\n",
       "      <td>0.021535</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>3.137068</td>\n",
       "      <td>0.377582</td>\n",
       "      <td>3.892536</td>\n",
       "      <td>7.198916</td>\n",
       "      <td>7.722409</td>\n",
       "      <td>0.635818</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>1.503395</td>\n",
       "      <td>2.257621</td>\n",
       "      <td>4.925860</td>\n",
       "      <td>0.068937</td>\n",
       "      <td>0.667931</td>\n",
       "      <td>1.711907</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.410749</td>\n",
       "      <td>1.521779</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>0.237557</td>\n",
       "      <td>1.154172</td>\n",
       "      <td>0.648396</td>\n",
       "      <td>0.677608</td>\n",
       "      <td>0.689399</td>\n",
       "      <td>0.072162</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>8.305739</td>\n",
       "      <td>3.880816</td>\n",
       "      <td>4.457189</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>4.530211</td>\n",
       "      <td>0.909127</td>\n",
       "      <td>1.269520</td>\n",
       "      <td>3.326457</td>\n",
       "      <td>6.928039</td>\n",
       "      <td>0.016482</td>\n",
       "      <td>0.212037</td>\n",
       "      <td>1.583018</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.089141</td>\n",
       "      <td>1.514105</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.046138</td>\n",
       "      <td>1.389082</td>\n",
       "      <td>-0.741757</td>\n",
       "      <td>0.655603</td>\n",
       "      <td>0.687804</td>\n",
       "      <td>0.691104</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>-0.043376</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>0.185959</td>\n",
       "      <td>0.823324</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>1.434530</td>\n",
       "      <td>0.916156</td>\n",
       "      <td>1.602828</td>\n",
       "      <td>2.195532</td>\n",
       "      <td>0.808134</td>\n",
       "      <td>1.552481</td>\n",
       "      <td>2.167955</td>\n",
       "      <td>0.570696</td>\n",
       "      <td>1.428605</td>\n",
       "      <td>2.059210</td>\n",
       "      <td>0.334736</td>\n",
       "      <td>-0.581778</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>0.015972</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>2.727133</td>\n",
       "      <td>0.378616</td>\n",
       "      <td>3.467151</td>\n",
       "      <td>7.487552</td>\n",
       "      <td>7.433791</td>\n",
       "      <td>0.635407</td>\n",
       "      <td>0.941483</td>\n",
       "      <td>1.464557</td>\n",
       "      <td>1.723027</td>\n",
       "      <td>3.673968</td>\n",
       "      <td>0.185457</td>\n",
       "      <td>0.896319</td>\n",
       "      <td>1.748199</td>\n",
       "      <td>0.078212</td>\n",
       "      <td>0.587950</td>\n",
       "      <td>1.387481</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.351934</td>\n",
       "      <td>0.954275</td>\n",
       "      <td>0.594566</td>\n",
       "      <td>0.648752</td>\n",
       "      <td>0.678988</td>\n",
       "      <td>0.088484</td>\n",
       "      <td>0.067934</td>\n",
       "      <td>0.035201</td>\n",
       "      <td>8.308981</td>\n",
       "      <td>3.754670</td>\n",
       "      <td>4.587977</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>4.560084</td>\n",
       "      <td>0.980085</td>\n",
       "      <td>1.412619</td>\n",
       "      <td>3.396073</td>\n",
       "      <td>6.981920</td>\n",
       "      <td>0.014798</td>\n",
       "      <td>0.174807</td>\n",
       "      <td>1.545654</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.067891</td>\n",
       "      <td>1.464643</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.034822</td>\n",
       "      <td>1.302994</td>\n",
       "      <td>-0.524230</td>\n",
       "      <td>0.666491</td>\n",
       "      <td>0.688602</td>\n",
       "      <td>0.691445</td>\n",
       "      <td>0.022201</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>-0.021335</td>\n",
       "      <td>0.020272</td>\n",
       "      <td>0.162766</td>\n",
       "      <td>0.849688</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>1.051621</td>\n",
       "      <td>1.194038</td>\n",
       "      <td>1.757186</td>\n",
       "      <td>2.283189</td>\n",
       "      <td>1.187692</td>\n",
       "      <td>1.750634</td>\n",
       "      <td>2.276315</td>\n",
       "      <td>1.093393</td>\n",
       "      <td>1.690754</td>\n",
       "      <td>2.173004</td>\n",
       "      <td>0.201384</td>\n",
       "      <td>-0.269427</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.028832</td>\n",
       "      <td>0.020869</td>\n",
       "      <td>3.529859</td>\n",
       "      <td>0.199491</td>\n",
       "      <td>5.017339</td>\n",
       "      <td>6.521595</td>\n",
       "      <td>6.443537</td>\n",
       "      <td>0.680732</td>\n",
       "      <td>1.255359</td>\n",
       "      <td>2.192933</td>\n",
       "      <td>3.025006</td>\n",
       "      <td>6.261767</td>\n",
       "      <td>0.033034</td>\n",
       "      <td>0.274310</td>\n",
       "      <td>1.225120</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.114095</td>\n",
       "      <td>0.835978</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.059348</td>\n",
       "      <td>0.526151</td>\n",
       "      <td>0.683005</td>\n",
       "      <td>0.690195</td>\n",
       "      <td>0.691672</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>7.574697</td>\n",
       "      <td>3.972081</td>\n",
       "      <td>3.647517</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>4.404826</td>\n",
       "      <td>0.995002</td>\n",
       "      <td>1.526862</td>\n",
       "      <td>2.196236</td>\n",
       "      <td>4.947366</td>\n",
       "      <td>0.035010</td>\n",
       "      <td>0.792266</td>\n",
       "      <td>1.797087</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.539025</td>\n",
       "      <td>1.679993</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.322333</td>\n",
       "      <td>1.493337</td>\n",
       "      <td>-0.377208</td>\n",
       "      <td>0.537143</td>\n",
       "      <td>0.611194</td>\n",
       "      <td>0.647210</td>\n",
       "      <td>0.029273</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0.009703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>-0.029722</td>\n",
       "      <td>0.041424</td>\n",
       "      <td>-0.172067</td>\n",
       "      <td>0.851083</td>\n",
       "      <td>0.147616</td>\n",
       "      <td>1.405038</td>\n",
       "      <td>1.007265</td>\n",
       "      <td>1.647133</td>\n",
       "      <td>2.220460</td>\n",
       "      <td>0.930979</td>\n",
       "      <td>1.602793</td>\n",
       "      <td>2.195634</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>1.483389</td>\n",
       "      <td>2.092674</td>\n",
       "      <td>0.129384</td>\n",
       "      <td>-0.121491</td>\n",
       "      <td>0.021535</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>3.211773</td>\n",
       "      <td>0.220480</td>\n",
       "      <td>4.580639</td>\n",
       "      <td>5.990585</td>\n",
       "      <td>6.801621</td>\n",
       "      <td>0.677576</td>\n",
       "      <td>1.325186</td>\n",
       "      <td>2.345032</td>\n",
       "      <td>2.599321</td>\n",
       "      <td>5.341599</td>\n",
       "      <td>0.069819</td>\n",
       "      <td>0.370088</td>\n",
       "      <td>1.397759</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.156785</td>\n",
       "      <td>1.138001</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.082437</td>\n",
       "      <td>0.829416</td>\n",
       "      <td>0.676340</td>\n",
       "      <td>0.685636</td>\n",
       "      <td>0.689512</td>\n",
       "      <td>0.025522</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>7.685521</td>\n",
       "      <td>3.981836</td>\n",
       "      <td>3.745949</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>4.408766</td>\n",
       "      <td>0.870255</td>\n",
       "      <td>1.203772</td>\n",
       "      <td>2.492848</td>\n",
       "      <td>5.322527</td>\n",
       "      <td>0.063589</td>\n",
       "      <td>0.675134</td>\n",
       "      <td>1.773750</td>\n",
       "      <td>0.019461</td>\n",
       "      <td>0.478693</td>\n",
       "      <td>1.712419</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.294549</td>\n",
       "      <td>1.609046</td>\n",
       "      <td>-0.424152</td>\n",
       "      <td>0.514628</td>\n",
       "      <td>0.655014</td>\n",
       "      <td>0.679678</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1561 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "1475 -0.032028  0.034022  0.370835  0.864550 -0.118525  1.264972  1.037867   \n",
       "1808 -0.028646  0.025474  0.241102  0.875787  0.000252  1.107291  1.104043   \n",
       "587  -0.028829  0.030722  0.558112  0.933043  0.052116  1.316040  1.076122   \n",
       "1422 -0.039039  0.031770 -0.428119  0.840299 -0.233262  1.407018  1.009093   \n",
       "364  -0.039183  0.033302  0.374027  0.856410  0.047072  1.464493  0.992642   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "256  -0.035565  0.039064 -0.117074  0.871342  0.153608  1.438789  0.986350   \n",
       "1561 -0.042378  0.037097  0.191929  0.857969 -0.011552  1.415862  0.954682   \n",
       "1764 -0.043376  0.041127  0.185959  0.823324  0.026015  1.434530  0.916156   \n",
       "885  -0.021335  0.020272  0.162766  0.849688  0.043556  1.051621  1.194038   \n",
       "537  -0.029722  0.041424 -0.172067  0.851083  0.147616  1.405038  1.007265   \n",
       "\n",
       "      feature8  feature9  feature10  feature11  feature12  feature13  \\\n",
       "1475  1.667196  2.231905   0.967313   1.633548   2.212393   0.768427   \n",
       "1808  1.708234  2.255059   1.061015   1.688804   2.242157   0.987298   \n",
       "587   1.696325  2.248102   1.007588   1.659361   2.225989   0.807709   \n",
       "1422  1.652052  2.222776   0.924808   1.605831   2.196560   0.730227   \n",
       "364   1.643530  2.218347   0.895917   1.589784   2.188573   0.669859   \n",
       "...        ...       ...        ...        ...        ...        ...   \n",
       "256   1.632967  2.210680   0.905143   1.585216   2.184549   0.703309   \n",
       "1561  1.620754  2.205050   0.859478   1.574328   2.179332   0.634716   \n",
       "1764  1.602828  2.195532   0.808134   1.552481   2.167955   0.570696   \n",
       "885   1.757186  2.283189   1.187692   1.750634   2.276315   1.093393   \n",
       "537   1.647133  2.220460   0.930979   1.602793   2.195634   0.810127   \n",
       "\n",
       "      feature14  feature15  feature16  feature17  feature18  feature19  \\\n",
       "1475   1.522354   2.110041   0.250438  -0.400312   0.040441   0.012395   \n",
       "1808   1.602304   2.161056   0.116854  -0.104198   0.013626   0.014743   \n",
       "587    1.543810   2.113079   0.147325  -0.192890   0.019536   0.012171   \n",
       "1422   1.472869   2.076597   0.167599  -0.185110   0.036513   0.012730   \n",
       "364    1.446585   2.084488   0.233070  -0.165172   0.030813   0.010826   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    1.466739   2.076597   0.088099  -0.065504   0.011050   0.002491   \n",
       "1561   1.461436   2.064042   0.364807  -0.491284   0.072057   0.021535   \n",
       "1764   1.428605   2.059210   0.334736  -0.581778   0.059744   0.015972   \n",
       "885    1.690754   2.173004   0.201384  -0.269427   0.033009   0.028832   \n",
       "537    1.483389   2.092674   0.129384  -0.121491   0.021535   0.006104   \n",
       "\n",
       "      feature20  feature21  feature22  feature23  feature24  feature25  \\\n",
       "1475   0.001586   3.659839   0.240309   4.944186   6.274369   7.086494   \n",
       "1808   0.004525   3.765178   0.141159   5.631786   5.406202   6.080642   \n",
       "587    0.002491   3.439345   0.168664   5.107136   5.429961   6.446549   \n",
       "1422   0.002265   2.978628   0.260340   4.155009   6.433919   6.726297   \n",
       "364    0.004299   2.668223   0.275654   3.767326   6.591060   6.646252   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    0.000907   3.195003   0.163118   4.891328   5.575766   5.665346   \n",
       "1561   0.003170   3.137068   0.377582   3.892536   7.198916   7.722409   \n",
       "1764   0.002265   2.727133   0.378616   3.467151   7.487552   7.433791   \n",
       "885    0.020869   3.529859   0.199491   5.017339   6.521595   6.443537   \n",
       "537    0.000907   3.211773   0.220480   4.580639   5.990585   6.801621   \n",
       "\n",
       "      feature26  feature27  feature28  feature29  feature30  feature31  \\\n",
       "1475   0.674185   1.071766   1.661296   3.124062   6.541088   0.019055   \n",
       "1808   0.687393   1.499706   2.834561   3.366765   6.908809   0.014798   \n",
       "587    0.684600   1.274247   2.103799   2.928116   6.008690   0.041780   \n",
       "1422   0.670438   1.003988   1.780174   2.109490   4.421180   0.109141   \n",
       "364    0.666955   0.973778   1.688577   1.910258   3.921696   0.208552   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    0.685257   1.239461   2.327382   2.526754   5.187216   0.085485   \n",
       "1561   0.635818   0.988602   1.503395   2.257621   4.925860   0.068937   \n",
       "1764   0.635407   0.941483   1.464557   1.723027   3.673968   0.185457   \n",
       "885    0.680732   1.255359   2.192933   3.025006   6.261767   0.033034   \n",
       "537    0.677576   1.325186   2.345032   2.599321   5.341599   0.069819   \n",
       "\n",
       "      feature32  feature33  feature34  feature35  feature36  feature37  \\\n",
       "1475   0.247181   1.310267   0.004572   0.101472   0.927177   0.002289   \n",
       "1808   0.139580   0.886182   0.003267   0.046226   0.472858   0.001635   \n",
       "587    0.203219   1.118452   0.011074   0.068792   0.682258   0.005557   \n",
       "1422   0.574387   1.365110   0.037339   0.272998   0.877849   0.018920   \n",
       "364    0.700264   1.467657   0.086885   0.351484   0.952540   0.044846   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    0.313682   0.988456   0.027166   0.112475   0.529659   0.013711   \n",
       "1561   0.667931   1.711907   0.021390   0.410749   1.521779   0.010778   \n",
       "1764   0.896319   1.748199   0.078212   0.587950   1.387481   0.040323   \n",
       "885    0.274310   1.225120   0.008477   0.114095   0.835978   0.004250   \n",
       "537    0.370088   1.397759   0.020760   0.156785   1.138001   0.010452   \n",
       "\n",
       "      feature38  feature39  feature40  feature41  feature42  feature43  \\\n",
       "1475   0.052588   0.587749   0.684493   0.690650   0.692353   0.016195   \n",
       "1808   0.023471   0.267950   0.688829   0.691445   0.692580   0.008130   \n",
       "587    0.035146   0.405570   0.686207   0.689285   0.691218   0.009029   \n",
       "1422   0.147494   0.547120   0.649108   0.669514   0.686549   0.037169   \n",
       "364    0.193625   0.598205   0.637548   0.658072   0.677377   0.034325   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    0.058061   0.304742   0.677377   0.683692   0.688374   0.012842   \n",
       "1561   0.237557   1.154172   0.648396   0.677608   0.689399   0.072162   \n",
       "1764   0.351934   0.954275   0.594566   0.648752   0.678988   0.088484   \n",
       "885    0.059348   0.526151   0.683005   0.690195   0.691672   0.014855   \n",
       "537    0.082437   0.829416   0.676340   0.685636   0.689512   0.025522   \n",
       "\n",
       "      feature44  feature45  feature46  feature47  feature48  feature49  \\\n",
       "1475   0.004073   0.002717   7.781603   4.120589   3.701950   0.021278   \n",
       "1808   0.002717   0.001360   7.198170   4.185365   3.074695   0.020022   \n",
       "587    0.004525   0.003170   7.390991   4.072976   3.369581   0.017481   \n",
       "1422   0.034106   0.011274   7.871486   3.853629   4.056370   0.010954   \n",
       "364    0.037388   0.026847   7.937489   3.777310   4.198110   0.009996   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    0.012171   0.008130   7.353950   3.925098   3.479458   0.015751   \n",
       "1561   0.021979   0.009479   8.305739   3.880816   4.457189   0.010986   \n",
       "1764   0.067934   0.035201   8.308981   3.754670   4.587977   0.008536   \n",
       "885    0.003622   0.002717   7.574697   3.972081   3.647517   0.010364   \n",
       "537    0.008580   0.005878   7.685521   3.981836   3.745949   0.012762   \n",
       "\n",
       "      feature50  feature51  feature52  feature53  feature54  feature55  \\\n",
       "1475   0.030081   4.345690   0.751574   1.033199   2.647241   5.802115   \n",
       "1808   0.027705   4.255801   0.788180   1.080784   1.902870   4.256025   \n",
       "587    0.026906   4.344429   0.827322   1.147865   2.175402   4.700574   \n",
       "1422   0.024327   4.470633   0.918773   1.283796   2.942992   6.077320   \n",
       "364    0.023464   4.497436   0.943759   1.334856   3.063163   6.275750   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    0.025401   4.411846   0.830766   1.160258   2.391564   4.947398   \n",
       "1561   0.023603   4.530211   0.909127   1.269520   3.326457   6.928039   \n",
       "1764   0.021553   4.560084   0.980085   1.412619   3.396073   6.981920   \n",
       "885    0.015899   4.404826   0.995002   1.526862   2.196236   4.947366   \n",
       "537    0.023621   4.408766   0.870255   1.203772   2.492848   5.322527   \n",
       "\n",
       "      feature56  feature57  feature58  feature59  feature60  feature61  \\\n",
       "1475   0.038913   0.710238   1.792275   0.011068   0.540995   1.740721   \n",
       "1808   0.133624   1.074274   1.933360   0.049278   0.959709   1.889386   \n",
       "587    0.097515   0.914317   1.864827   0.032889   0.779708   1.813913   \n",
       "1422   0.037922   0.390315   1.680479   0.009777   0.196946   1.627172   \n",
       "364    0.024897   0.331638   1.651574   0.005876   0.160074   1.589612   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    0.092648   0.844998   1.835887   0.028467   0.669556   1.776921   \n",
       "1561   0.016482   0.212037   1.583018   0.003919   0.089141   1.514105   \n",
       "1764   0.014798   0.174807   1.545654   0.003267   0.067891   1.464643   \n",
       "885    0.035010   0.792266   1.797087   0.009126   0.539025   1.679993   \n",
       "537    0.063589   0.675134   1.773750   0.019461   0.478693   1.712419   \n",
       "\n",
       "      feature62  feature63  feature64  feature65  feature66  feature67  \\\n",
       "1475   0.005557   0.346385   1.622876  -0.529971   0.474529   0.642570   \n",
       "1808   0.025095   0.760833   1.781143  -0.262815   0.296824   0.484915   \n",
       "587    0.016642   0.565027   1.673684  -0.307062   0.396963   0.575619   \n",
       "1422   0.004903   0.106031   1.536250  -0.244566   0.600679   0.681056   \n",
       "364    0.002943   0.084994   1.465978  -0.262432   0.617206   0.683578   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "256    0.014363   0.452514   1.629425  -0.125965   0.436718   0.612670   \n",
       "1561   0.001962   0.046138   1.389082  -0.741757   0.655603   0.687804   \n",
       "1764   0.001635   0.034822   1.302994  -0.524230   0.666491   0.688602   \n",
       "885    0.004577   0.322333   1.493337  -0.377208   0.537143   0.611194   \n",
       "537    0.009800   0.294549   1.609046  -0.424152   0.514628   0.655014   \n",
       "\n",
       "      feature68  feature69  feature70  feature71  \n",
       "1475   0.679218   0.049977   0.016418   0.006104  \n",
       "1808   0.595067   0.024637   0.017087   0.015748  \n",
       "587    0.647803   0.032570   0.016195   0.008355  \n",
       "1422   0.687120   0.037606   0.003847   0.002039  \n",
       "364    0.688488   0.025522   0.002717   0.001133  \n",
       "...         ...        ...        ...        ...  \n",
       "256    0.664276   0.024195   0.010377   0.004299  \n",
       "1561   0.691104   0.027950   0.002944   0.000227  \n",
       "1764   0.691445   0.022201   0.003396   0.001133  \n",
       "885    0.647210   0.029273   0.014632   0.009703  \n",
       "537    0.679678   0.041094   0.012842   0.002944  \n",
       "\n",
       "[1561 rows x 71 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_results = df_results.drop('log', axis=1)\n",
    "def log_normalization(data):\n",
    "    return np.log(data + 1)\n",
    "\n",
    "X_log = log_normalization(X)\n",
    "index_before_drop = X_log.index\n",
    "X_log.dropna(inplace=True)\n",
    "index_after_drop = X_log.index\n",
    "dropped_index = set(index_before_drop) - set(index_after_drop)\n",
    "y_log = y[~y.index.isin(dropped_index)]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b48209a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AdaBoostClassifier - Accuracy: 0.78 (+/- 0.01)\n",
      " BernoulliNB - Accuracy: 0.57 (+/- 0.05)\n",
      " DecisionTreeClassifier - Accuracy: 0.76 (+/- 0.08)\n",
      " ExtraTreeClassifier - Accuracy: 0.75 (+/- 0.06)\n",
      " ExtraTreesClassifier - Accuracy: 0.90 (+/- 0.03)\n",
      " GaussianNB - Accuracy: 0.64 (+/- 0.07)\n",
      " GradientBoostingClassifier - Accuracy: 0.86 (+/- 0.04)\n",
      " HistGradientBoostingClassifier - Accuracy: 0.91 (+/- 0.03)\n",
      " KNeighborsClassifier - Accuracy: 0.82 (+/- 0.04)\n",
      " LabelPropagation - Accuracy: 0.84 (+/- 0.03)\n",
      " LabelSpreading - Accuracy: 0.84 (+/- 0.03)\n",
      " LinearDiscriminantAnalysis - Accuracy: 0.79 (+/- 0.04)\n",
      " LinearSVC - Accuracy: 0.75 (+/- 0.04)\n",
      " LogisticRegression - Accuracy: 0.73 (+/- 0.03)\n",
      " MLPClassifier - Accuracy: 0.72 (+/- 0.02)\n",
      "MultinomialNB - Valeurs d'entrée non conformes\n",
      " NearestCentroid - Accuracy: 0.53 (+/- 0.07)\n",
      " NuSVC - Accuracy: 0.80 (+/- 0.03)\n",
      " QuadraticDiscriminantAnalysis - Accuracy: 0.83 (+/- 0.05)\n",
      " RandomForestClassifier - Accuracy: 0.89 (+/- 0.04)\n",
      " RidgeClassifier - Accuracy: 0.75 (+/- 0.03)\n",
      " SGDClassifier - Accuracy: 0.61 (+/- 0.13)\n",
      " SVC - Accuracy: 0.59 (+/- 0.05)\n",
      " XGBClassifier - Accuracy: 0.90 (+/- 0.03)\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5380 - accuracy: 0.7084\n",
      "Réseau Neuronel - Test loss: 0.537964403629303  Test accuracy: 0.7084398865699768  Training time : 68.89 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>default</th>\n",
       "      <th>normalized</th>\n",
       "      <th>standardized</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.897236</td>\n",
       "      <td>0.897236</td>\n",
       "      <td>0.896605</td>\n",
       "      <td>0.910326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.893457</td>\n",
       "      <td>0.894725</td>\n",
       "      <td>0.887782</td>\n",
       "      <td>0.897506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.885261</td>\n",
       "      <td>0.885261</td>\n",
       "      <td>0.885261</td>\n",
       "      <td>0.895578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.884005</td>\n",
       "      <td>0.885265</td>\n",
       "      <td>0.881475</td>\n",
       "      <td>0.891106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.853102</td>\n",
       "      <td>0.852473</td>\n",
       "      <td>0.851215</td>\n",
       "      <td>0.861633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.834194</td>\n",
       "      <td>0.812771</td>\n",
       "      <td>0.844337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.498738</td>\n",
       "      <td>0.831046</td>\n",
       "      <td>0.812771</td>\n",
       "      <td>0.843057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.805831</td>\n",
       "      <td>0.805831</td>\n",
       "      <td>0.805831</td>\n",
       "      <td>0.827673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.791318</td>\n",
       "      <td>0.832296</td>\n",
       "      <td>0.831030</td>\n",
       "      <td>0.820011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>0.767982</td>\n",
       "      <td>0.817818</td>\n",
       "      <td>0.829163</td>\n",
       "      <td>0.801415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.776813</td>\n",
       "      <td>0.776813</td>\n",
       "      <td>0.776813</td>\n",
       "      <td>0.793082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.774926</td>\n",
       "      <td>0.774295</td>\n",
       "      <td>0.774295</td>\n",
       "      <td>0.775778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.778678</td>\n",
       "      <td>0.776791</td>\n",
       "      <td>0.783098</td>\n",
       "      <td>0.760443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.742150</td>\n",
       "      <td>0.720070</td>\n",
       "      <td>0.769254</td>\n",
       "      <td>0.752068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.756636</td>\n",
       "      <td>0.753483</td>\n",
       "      <td>0.768617</td>\n",
       "      <td>0.751436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.539109</td>\n",
       "      <td>0.728276</td>\n",
       "      <td>0.766095</td>\n",
       "      <td>0.748863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.658278</td>\n",
       "      <td>0.689820</td>\n",
       "      <td>0.749084</td>\n",
       "      <td>0.728373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.683535</td>\n",
       "      <td>0.774307</td>\n",
       "      <td>0.864453</td>\n",
       "      <td>0.723255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Neuronal Network</td>\n",
       "      <td>0.672544</td>\n",
       "      <td>0.788413</td>\n",
       "      <td>0.836272</td>\n",
       "      <td>0.708440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.643136</td>\n",
       "      <td>0.657643</td>\n",
       "      <td>0.657643</td>\n",
       "      <td>0.638691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.503155</td>\n",
       "      <td>0.703660</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>0.613060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.653870</td>\n",
       "      <td>0.687925</td>\n",
       "      <td>0.774305</td>\n",
       "      <td>0.588736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.558614</td>\n",
       "      <td>0.513874</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.568229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.525280</td>\n",
       "      <td>0.592651</td>\n",
       "      <td>0.600855</td>\n",
       "      <td>0.525952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model_name   default  normalized  standardized  \\\n",
       "7   HistGradientBoostingClassifier  0.897236    0.897236      0.896605   \n",
       "4             ExtraTreesClassifier  0.893457    0.894725      0.887782   \n",
       "23                   XGBClassifier  0.885261    0.885261      0.885261   \n",
       "19          RandomForestClassifier  0.884005    0.885265      0.881475   \n",
       "6       GradientBoostingClassifier  0.853102    0.852473      0.851215   \n",
       "9                 LabelPropagation  0.498738    0.834194      0.812771   \n",
       "10                  LabelSpreading  0.498738    0.831046      0.812771   \n",
       "18   QuadraticDiscriminantAnalysis  0.805831    0.805831      0.805831   \n",
       "8             KNeighborsClassifier  0.791318    0.832296      0.831030   \n",
       "17                           NuSVC  0.767982    0.817818      0.829163   \n",
       "11      LinearDiscriminantAnalysis  0.776813    0.776813      0.776813   \n",
       "0               AdaBoostClassifier  0.774926    0.774295      0.774295   \n",
       "2           DecisionTreeClassifier  0.778678    0.776791      0.783098   \n",
       "20                 RidgeClassifier  0.742150    0.720070      0.769254   \n",
       "3              ExtraTreeClassifier  0.756636    0.753483      0.768617   \n",
       "12                       LinearSVC  0.539109    0.728276      0.766095   \n",
       "13              LogisticRegression  0.658278    0.689820      0.749084   \n",
       "14                   MLPClassifier  0.683535    0.774307      0.864453   \n",
       "24                Neuronal Network  0.672544    0.788413      0.836272   \n",
       "5                       GaussianNB  0.643136    0.657643      0.657643   \n",
       "21                   SGDClassifier  0.503155    0.703660      0.704301   \n",
       "22                             SVC  0.653870    0.687925      0.774305   \n",
       "1                      BernoulliNB  0.558614    0.513874      0.564270   \n",
       "16                 NearestCentroid  0.525280    0.592651      0.600855   \n",
       "15                   MultinomialNB  0.000000    0.592016      0.000000   \n",
       "\n",
       "         log  \n",
       "7   0.910326  \n",
       "4   0.897506  \n",
       "23  0.895578  \n",
       "19  0.891106  \n",
       "6   0.861633  \n",
       "9   0.844337  \n",
       "10  0.843057  \n",
       "18  0.827673  \n",
       "8   0.820011  \n",
       "17  0.801415  \n",
       "11  0.793082  \n",
       "0   0.775778  \n",
       "2   0.760443  \n",
       "20  0.752068  \n",
       "3   0.751436  \n",
       "12  0.748863  \n",
       "13  0.728373  \n",
       "14  0.723255  \n",
       "24  0.708440  \n",
       "5   0.638691  \n",
       "21  0.613060  \n",
       "22  0.588736  \n",
       "1   0.568229  \n",
       "16  0.525952  \n",
       "15  0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scores = []\n",
    "for model in model_names :     \n",
    "    sc = launch_model(model)\n",
    "    log_scores.append(sc)\n",
    "sc_nn = launch_NN()\n",
    "log_scores.append(sc_nn)\n",
    "df_results['log'] = log_scores\n",
    "df_results.sort_values('log', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe1601",
   "metadata": {},
   "source": [
    " <a id=\"3\"></a>\n",
    " <div>\n",
    "    <h2 style=\"font-size:1.8em; color: #286fee;text-decoration:underline; letter-spacing:1px\">III - Augmentation des données </h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5124a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_names = [\n",
    "     LogisticRegression(),\n",
    "    ExtraTreesClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    HistGradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    xgb.XGBClassifier(objective='binary:logistic')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62120d69",
   "metadata": {},
   "source": [
    "**Augmentation / Diminution des données par segmentation des sons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29af2225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#echantillons de 0.1s\n",
    "file1 = r'../Data/data2'\n",
    "df1 = pd.read_pickle(file1)\n",
    "df1.name = \"0.1s\"\n",
    "\n",
    "#echantillons de 0.2s\n",
    "file2 = r'../Data/data'\n",
    "df2 = pd.read_pickle(file2)\n",
    "df2.name = \"0.2s\"\n",
    "\n",
    "\n",
    "#echantillons de 0.5s\n",
    "file3 = r'../Data/data3'\n",
    "df3 = pd.read_pickle(file3)\n",
    "df3.name = \"0.5s\"\n",
    "\n",
    "\n",
    "dataframes = [df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035c66e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Echantillons de 0.1s ( 3969 données ) =========\n",
      "\n",
      " LogisticRegression - Accuracy: 0.72 (+/- 0.02)\n",
      " ExtraTreesClassifier - Accuracy: 0.89 (+/- 0.02)\n",
      " GradientBoostingClassifier - Accuracy: 0.85 (+/- 0.03)\n",
      " HistGradientBoostingClassifier - Accuracy: 0.90 (+/- 0.02)\n",
      " RandomForestClassifier - Accuracy: 0.89 (+/- 0.02)\n",
      " XGBClassifier - Accuracy: 0.90 (+/- 0.02)\n",
      "\n",
      "========= Echantillons de 0.2s ( 1983 données ) =========\n",
      "\n",
      " LogisticRegression - Accuracy: 0.73 (+/- 0.03)\n",
      " ExtraTreesClassifier - Accuracy: 0.90 (+/- 0.05)\n",
      " GradientBoostingClassifier - Accuracy: 0.86 (+/- 0.04)\n",
      " HistGradientBoostingClassifier - Accuracy: 0.91 (+/- 0.03)\n",
      " RandomForestClassifier - Accuracy: 0.89 (+/- 0.05)\n",
      " XGBClassifier - Accuracy: 0.90 (+/- 0.03)\n",
      "\n",
      "========= Echantillons de 0.5s ( 792 données ) =========\n",
      "\n",
      " LogisticRegression - Accuracy: 0.70 (+/- 0.07)\n",
      " ExtraTreesClassifier - Accuracy: 0.89 (+/- 0.06)\n",
      " GradientBoostingClassifier - Accuracy: 0.83 (+/- 0.08)\n",
      " HistGradientBoostingClassifier - Accuracy: 0.87 (+/- 0.04)\n",
      " RandomForestClassifier - Accuracy: 0.87 (+/- 0.03)\n",
      " XGBClassifier - Accuracy: 0.86 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "for df in dataframes :\n",
    "    print(f\"\\n========= Echantillons de {df.name} ( {len(df)} données ) =========\\n\")\n",
    "    X = df.select_dtypes(include=['int', 'float'])\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    # transformation des labels car/truck en 0 et 1\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    target1 = unique[0]\n",
    "    target2 = unique[1]       \n",
    "    y.replace(to_replace=target1, value=0, inplace=True)\n",
    "    y.replace(to_replace=target2, value=1, inplace=True)    \n",
    "    \n",
    "    #mise à l'échelle logarithmique\n",
    "    X_log = log_normalization(X)\n",
    "    index_before_drop = X_log.index\n",
    "    X_log.dropna(inplace=True)\n",
    "    index_after_drop = X_log.index\n",
    "    dropped_index = set(index_before_drop) - set(index_after_drop)\n",
    "    y_log = y[~y.index.isin(dropped_index)]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "    for best_model in best_model_names :     \n",
    "        sc = launch_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62247a4a",
   "metadata": {},
   "source": [
    "**Augmentation des données par création de sons factices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a009f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(row, mean=0, stddev=0.2):\n",
    "    noise = np.random.normal(mean, stddev, row.shape)\n",
    "    return row + noise\n",
    "\n",
    "file = r'../Data/data'\n",
    "df = pd.read_pickle(file)\n",
    "df.name = \"original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1049fe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 1 : 4 données \n",
      "Terminé !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>feature22</th>\n",
       "      <th>feature23</th>\n",
       "      <th>feature24</th>\n",
       "      <th>feature25</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>feature35</th>\n",
       "      <th>feature36</th>\n",
       "      <th>feature37</th>\n",
       "      <th>feature38</th>\n",
       "      <th>feature39</th>\n",
       "      <th>feature40</th>\n",
       "      <th>feature41</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>feature51</th>\n",
       "      <th>feature52</th>\n",
       "      <th>feature53</th>\n",
       "      <th>feature54</th>\n",
       "      <th>feature55</th>\n",
       "      <th>feature56</th>\n",
       "      <th>feature57</th>\n",
       "      <th>feature58</th>\n",
       "      <th>feature59</th>\n",
       "      <th>feature60</th>\n",
       "      <th>feature61</th>\n",
       "      <th>feature62</th>\n",
       "      <th>feature63</th>\n",
       "      <th>feature64</th>\n",
       "      <th>feature65</th>\n",
       "      <th>feature66</th>\n",
       "      <th>feature67</th>\n",
       "      <th>feature68</th>\n",
       "      <th>feature69</th>\n",
       "      <th>feature70</th>\n",
       "      <th>feature71</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.027537</td>\n",
       "      <td>0.030757</td>\n",
       "      <td>-0.234750</td>\n",
       "      <td>1.400160</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>2.534833</td>\n",
       "      <td>1.965961</td>\n",
       "      <td>4.468279</td>\n",
       "      <td>8.480426</td>\n",
       "      <td>1.781501</td>\n",
       "      <td>4.295799</td>\n",
       "      <td>8.292971</td>\n",
       "      <td>1.275652</td>\n",
       "      <td>3.594810</td>\n",
       "      <td>7.406123</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>-0.051207</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>27.854098</td>\n",
       "      <td>0.146360</td>\n",
       "      <td>190.312557</td>\n",
       "      <td>218.904421</td>\n",
       "      <td>248.848127</td>\n",
       "      <td>0.989258</td>\n",
       "      <td>4.254340</td>\n",
       "      <td>28.803362</td>\n",
       "      <td>16.002388</td>\n",
       "      <td>326.829977</td>\n",
       "      <td>0.059505</td>\n",
       "      <td>0.189759</td>\n",
       "      <td>1.455967</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.053382</td>\n",
       "      <td>0.612735</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.312147</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.990703</td>\n",
       "      <td>0.994104</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>1290.224519</td>\n",
       "      <td>57.195645</td>\n",
       "      <td>22.558090</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>0.024924</td>\n",
       "      <td>75.744920</td>\n",
       "      <td>1.294533</td>\n",
       "      <td>2.174763</td>\n",
       "      <td>6.876299</td>\n",
       "      <td>74.304180</td>\n",
       "      <td>0.172410</td>\n",
       "      <td>1.739677</td>\n",
       "      <td>5.712770</td>\n",
       "      <td>0.060487</td>\n",
       "      <td>1.389278</td>\n",
       "      <td>5.409682</td>\n",
       "      <td>0.030415</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>4.705684</td>\n",
       "      <td>-0.148203</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.693424</td>\n",
       "      <td>0.878458</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.015646</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.034416</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>-0.241479</td>\n",
       "      <td>1.328176</td>\n",
       "      <td>-0.039620</td>\n",
       "      <td>2.797240</td>\n",
       "      <td>1.861350</td>\n",
       "      <td>4.369911</td>\n",
       "      <td>8.385962</td>\n",
       "      <td>1.665802</td>\n",
       "      <td>4.169244</td>\n",
       "      <td>8.178381</td>\n",
       "      <td>1.199297</td>\n",
       "      <td>3.626783</td>\n",
       "      <td>7.248582</td>\n",
       "      <td>0.065070</td>\n",
       "      <td>-0.061850</td>\n",
       "      <td>0.013832</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>32.834641</td>\n",
       "      <td>0.169388</td>\n",
       "      <td>193.843195</td>\n",
       "      <td>248.424499</td>\n",
       "      <td>325.872468</td>\n",
       "      <td>0.993637</td>\n",
       "      <td>1.872548</td>\n",
       "      <td>5.827316</td>\n",
       "      <td>18.917584</td>\n",
       "      <td>498.810148</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.315312</td>\n",
       "      <td>1.439119</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.113290</td>\n",
       "      <td>0.529923</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.057055</td>\n",
       "      <td>0.267359</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.991610</td>\n",
       "      <td>0.997506</td>\n",
       "      <td>0.021995</td>\n",
       "      <td>0.013379</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>1482.119004</td>\n",
       "      <td>58.167337</td>\n",
       "      <td>25.480262</td>\n",
       "      <td>0.032152</td>\n",
       "      <td>0.035699</td>\n",
       "      <td>75.345271</td>\n",
       "      <td>0.784097</td>\n",
       "      <td>1.361535</td>\n",
       "      <td>8.497949</td>\n",
       "      <td>128.012515</td>\n",
       "      <td>0.048187</td>\n",
       "      <td>1.646209</td>\n",
       "      <td>5.631705</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>1.250424</td>\n",
       "      <td>5.260538</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.775086</td>\n",
       "      <td>4.614710</td>\n",
       "      <td>-0.117724</td>\n",
       "      <td>0.458277</td>\n",
       "      <td>0.745578</td>\n",
       "      <td>0.886621</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.492385</td>\n",
       "      <td>-0.045307</td>\n",
       "      <td>-0.550019</td>\n",
       "      <td>1.722612</td>\n",
       "      <td>0.082251</td>\n",
       "      <td>2.371800</td>\n",
       "      <td>1.903909</td>\n",
       "      <td>4.350021</td>\n",
       "      <td>8.751397</td>\n",
       "      <td>1.291602</td>\n",
       "      <td>4.424693</td>\n",
       "      <td>8.266760</td>\n",
       "      <td>1.262551</td>\n",
       "      <td>3.305672</td>\n",
       "      <td>7.475723</td>\n",
       "      <td>-0.194154</td>\n",
       "      <td>0.177529</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>0.164282</td>\n",
       "      <td>27.543522</td>\n",
       "      <td>0.195094</td>\n",
       "      <td>190.271359</td>\n",
       "      <td>218.729215</td>\n",
       "      <td>248.931414</td>\n",
       "      <td>0.884443</td>\n",
       "      <td>4.175426</td>\n",
       "      <td>28.933766</td>\n",
       "      <td>15.958441</td>\n",
       "      <td>326.989773</td>\n",
       "      <td>-0.288621</td>\n",
       "      <td>0.091029</td>\n",
       "      <td>1.531073</td>\n",
       "      <td>0.191018</td>\n",
       "      <td>0.319272</td>\n",
       "      <td>0.612546</td>\n",
       "      <td>0.126802</td>\n",
       "      <td>-0.348081</td>\n",
       "      <td>0.304927</td>\n",
       "      <td>0.973256</td>\n",
       "      <td>0.780510</td>\n",
       "      <td>1.239233</td>\n",
       "      <td>-0.314316</td>\n",
       "      <td>0.056586</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>1290.480232</td>\n",
       "      <td>57.259087</td>\n",
       "      <td>22.674970</td>\n",
       "      <td>0.110366</td>\n",
       "      <td>-0.058058</td>\n",
       "      <td>76.013112</td>\n",
       "      <td>1.147532</td>\n",
       "      <td>2.339175</td>\n",
       "      <td>6.865712</td>\n",
       "      <td>73.913418</td>\n",
       "      <td>0.314753</td>\n",
       "      <td>2.007556</td>\n",
       "      <td>5.705472</td>\n",
       "      <td>0.090218</td>\n",
       "      <td>1.309079</td>\n",
       "      <td>5.697055</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>1.101172</td>\n",
       "      <td>4.790725</td>\n",
       "      <td>-0.078285</td>\n",
       "      <td>0.374509</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.863076</td>\n",
       "      <td>0.055455</td>\n",
       "      <td>0.215405</td>\n",
       "      <td>-0.310405</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.325840</td>\n",
       "      <td>-0.103252</td>\n",
       "      <td>-0.471445</td>\n",
       "      <td>1.124518</td>\n",
       "      <td>0.027975</td>\n",
       "      <td>3.147996</td>\n",
       "      <td>1.897869</td>\n",
       "      <td>4.355482</td>\n",
       "      <td>8.300564</td>\n",
       "      <td>1.554261</td>\n",
       "      <td>4.281784</td>\n",
       "      <td>8.921743</td>\n",
       "      <td>1.430802</td>\n",
       "      <td>3.813603</td>\n",
       "      <td>6.961439</td>\n",
       "      <td>0.055689</td>\n",
       "      <td>-0.234400</td>\n",
       "      <td>0.461681</td>\n",
       "      <td>-0.261211</td>\n",
       "      <td>-0.213031</td>\n",
       "      <td>32.623114</td>\n",
       "      <td>-0.125071</td>\n",
       "      <td>194.058759</td>\n",
       "      <td>248.283218</td>\n",
       "      <td>325.879649</td>\n",
       "      <td>1.206890</td>\n",
       "      <td>1.646794</td>\n",
       "      <td>5.662236</td>\n",
       "      <td>18.383534</td>\n",
       "      <td>498.746332</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>0.300912</td>\n",
       "      <td>1.380158</td>\n",
       "      <td>-0.062781</td>\n",
       "      <td>-0.011896</td>\n",
       "      <td>0.783810</td>\n",
       "      <td>-0.156830</td>\n",
       "      <td>-0.162536</td>\n",
       "      <td>0.307629</td>\n",
       "      <td>1.055892</td>\n",
       "      <td>0.748059</td>\n",
       "      <td>1.072542</td>\n",
       "      <td>0.056712</td>\n",
       "      <td>-0.027000</td>\n",
       "      <td>-0.053396</td>\n",
       "      <td>1482.354464</td>\n",
       "      <td>58.525209</td>\n",
       "      <td>25.521465</td>\n",
       "      <td>0.281340</td>\n",
       "      <td>0.045801</td>\n",
       "      <td>75.347932</td>\n",
       "      <td>0.982756</td>\n",
       "      <td>1.096720</td>\n",
       "      <td>8.874917</td>\n",
       "      <td>128.113955</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>1.749625</td>\n",
       "      <td>5.455132</td>\n",
       "      <td>0.120396</td>\n",
       "      <td>1.027958</td>\n",
       "      <td>5.141551</td>\n",
       "      <td>-0.059920</td>\n",
       "      <td>0.508808</td>\n",
       "      <td>4.624115</td>\n",
       "      <td>-0.554953</td>\n",
       "      <td>0.802051</td>\n",
       "      <td>0.812894</td>\n",
       "      <td>0.669618</td>\n",
       "      <td>-0.167366</td>\n",
       "      <td>-0.046695</td>\n",
       "      <td>-0.263357</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0 -0.027537  0.030757 -0.234750  1.400160 -0.000851  2.534833  1.965961   \n",
       "1 -0.034416  0.028287 -0.241479  1.328176 -0.039620  2.797240  1.861350   \n",
       "2  0.492385 -0.045307 -0.550019  1.722612  0.082251  2.371800  1.903909   \n",
       "3 -0.325840 -0.103252 -0.471445  1.124518  0.027975  3.147996  1.897869   \n",
       "\n",
       "   feature8  feature9  feature10  feature11  feature12  feature13  feature14  \\\n",
       "0  4.468279  8.480426   1.781501   4.295799   8.292971   1.275652   3.594810   \n",
       "1  4.369911  8.385962   1.665802   4.169244   8.178381   1.199297   3.626783   \n",
       "2  4.350021  8.751397   1.291602   4.424693   8.266760   1.262551   3.305672   \n",
       "3  4.355482  8.300564   1.554261   4.281784   8.921743   1.430802   3.813603   \n",
       "\n",
       "   feature15  feature16  feature17  feature18  feature19  feature20  \\\n",
       "0   7.406123   0.074980  -0.051207   0.009524   0.005782   0.000794   \n",
       "1   7.248582   0.065070  -0.061850   0.013832   0.007256   0.001814   \n",
       "2   7.475723  -0.194154   0.177529   0.051148   0.010165   0.164282   \n",
       "3   6.961439   0.055689  -0.234400   0.461681  -0.261211  -0.213031   \n",
       "\n",
       "   feature21  feature22   feature23   feature24   feature25  feature26  \\\n",
       "0  27.854098   0.146360  190.312557  218.904421  248.848127   0.989258   \n",
       "1  32.834641   0.169388  193.843195  248.424499  325.872468   0.993637   \n",
       "2  27.543522   0.195094  190.271359  218.729215  248.931414   0.884443   \n",
       "3  32.623114  -0.125071  194.058759  248.283218  325.879649   1.206890   \n",
       "\n",
       "   feature27  feature28  feature29   feature30  feature31  feature32  \\\n",
       "0   4.254340  28.803362  16.002388  326.829977   0.059505   0.189759   \n",
       "1   1.872548   5.827316  18.917584  498.810148   0.028882   0.315312   \n",
       "2   4.175426  28.933766  15.958441  326.989773  -0.288621   0.091029   \n",
       "3   1.646794   5.662236  18.383534  498.746332   0.048427   0.300912   \n",
       "\n",
       "   feature33  feature34  feature35  feature36  feature37  feature38  \\\n",
       "0   1.455967   0.017037   0.053382   0.612735   0.008531   0.026745   \n",
       "1   1.439119   0.007202   0.113290   0.529923   0.003603   0.057055   \n",
       "2   1.531073   0.191018   0.319272   0.612546   0.126802  -0.348081   \n",
       "3   1.380158  -0.062781  -0.011896   0.783810  -0.156830  -0.162536   \n",
       "\n",
       "   feature39  feature40  feature41  feature42  feature43  feature44  \\\n",
       "0   0.312147   0.985714   0.990703   0.994104   0.005896   0.004989   \n",
       "1   0.267359   0.971429   0.991610   0.997506   0.021995   0.013379   \n",
       "2   0.304927   0.973256   0.780510   1.239233  -0.314316   0.056586   \n",
       "3   0.307629   1.055892   0.748059   1.072542   0.056712  -0.027000   \n",
       "\n",
       "   feature45    feature46  feature47  feature48  feature49  feature50  \\\n",
       "0   0.004535  1290.224519  57.195645  22.558090   0.015494   0.024924   \n",
       "1   0.004762  1482.119004  58.167337  25.480262   0.032152   0.035699   \n",
       "2  -0.006054  1290.480232  57.259087  22.674970   0.110366  -0.058058   \n",
       "3  -0.053396  1482.354464  58.525209  25.521465   0.281340   0.045801   \n",
       "\n",
       "   feature51  feature52  feature53  feature54   feature55  feature56  \\\n",
       "0  75.744920   1.294533   2.174763   6.876299   74.304180   0.172410   \n",
       "1  75.345271   0.784097   1.361535   8.497949  128.012515   0.048187   \n",
       "2  76.013112   1.147532   2.339175   6.865712   73.913418   0.314753   \n",
       "3  75.347932   0.982756   1.096720   8.874917  128.113955   0.008242   \n",
       "\n",
       "   feature57  feature58  feature59  feature60  feature61  feature62  \\\n",
       "0   1.739677   5.712770   0.060487   1.389278   5.409682   0.030415   \n",
       "1   1.646209   5.631705   0.012451   1.250424   5.260538   0.006229   \n",
       "2   2.007556   5.705472   0.090218   1.309079   5.697055   0.001782   \n",
       "3   1.749625   5.455132   0.120396   1.027958   5.141551  -0.059920   \n",
       "\n",
       "   feature63  feature64  feature65  feature66  feature67  feature68  \\\n",
       "0   0.998692   4.705684  -0.148203   0.399546   0.693424   0.878458   \n",
       "1   0.775086   4.614710  -0.117724   0.458277   0.745578   0.886621   \n",
       "2   1.101172   4.790725  -0.078285   0.374509   0.742045   0.863076   \n",
       "3   0.508808   4.624115  -0.554953   0.802051   0.812894   0.669618   \n",
       "\n",
       "   feature69  feature70  feature71  label  \n",
       "0   0.019728   0.015646   0.007029    car  \n",
       "1   0.022676   0.012698   0.007256  truck  \n",
       "2   0.055455   0.215405  -0.310405    car  \n",
       "3  -0.167366  -0.046695  -0.263357  truck  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_sounds(df_to_fill, n_loop, fct):\n",
    "    empty_df = pd.DataFrame(columns=df_to_fill.columns)\n",
    "    for n in range(n_loop):\n",
    "        for i, row in df_to_fill.iterrows():\n",
    "            new_row = fct(row[:-1])\n",
    "            new_row['label'] = row[-1]\n",
    "            # append the noisy row to the noisy dataframe\n",
    "            empty_df = empty_df.append(pd.Series(new_row))\n",
    "            \n",
    "    \n",
    "        # concatenate the original dataframe and the noisy dataframe\n",
    "        df_to_fill = pd.concat([df_to_fill, empty_df], axis=0, ignore_index=True)\n",
    "        print(f\"Itération {n+1} : {len(df_to_fill)} données \")\n",
    "    print(\"Terminé !\")\n",
    "    if fct == add_noise :\n",
    "        df_to_fill.name = \"Noisy\"\n",
    "    return df_to_fill\n",
    "\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame([df.iloc[0], df.iloc[-1]], columns=df.columns)\n",
    "df_test_noisy = create_sounds(df_test, 1, add_noise)\n",
    "df_test_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "207a6792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 1 : 3966 données \n",
      "Terminé !\n",
      "Itération 1 : 7932 données \n",
      "Terminé !\n",
      "Itération 1 : 15864 données \n",
      "Itération 2 : 39660 données \n",
      "Terminé !\n"
     ]
    }
   ],
   "source": [
    "noisy_df = create_sounds(df, 1, add_noise)\n",
    "larger_noisy_df = create_sounds(noisy_df, 1 , add_noise)\n",
    "huge_noisy_df = create_sounds(larger_noisy_df, 2 , add_noise)\n",
    "\n",
    "dataframes = [df, noisy_df, larger_noisy_df, huge_noisy_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecfc2e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= original ( 1983 données ) =========\n",
      "\n",
      " LogisticRegression - Accuracy: 0.66 (+/- 0.06)\n",
      "Training time : 0.37\n",
      " ExtraTreesClassifier - Accuracy: 0.89 (+/- 0.03)\n",
      "Training time : 1.67\n",
      " GradientBoostingClassifier - Accuracy: 0.85 (+/- 0.03)\n",
      "Training time : 12.05\n",
      " HistGradientBoostingClassifier - Accuracy: 0.90 (+/- 0.03)\n",
      "Training time : 11.02\n",
      " RandomForestClassifier - Accuracy: 0.88 (+/- 0.04)\n",
      "Training time : 4.23\n",
      " XGBClassifier - Accuracy: 0.89 (+/- 0.03)\n",
      "Training time : 2.87\n",
      "\n",
      "========= Noisy ( 3966 données ) =========\n",
      "\n",
      " LogisticRegression - Accuracy: 0.66 (+/- 0.05)\n",
      "Training time : 0.45\n",
      " ExtraTreesClassifier - Accuracy: 0.87 (+/- 0.03)\n",
      "Training time : 3.02\n",
      " GradientBoostingClassifier - Accuracy: 0.83 (+/- 0.04)\n",
      "Training time : 26.42\n",
      " HistGradientBoostingClassifier - Accuracy: 0.89 (+/- 0.02)\n",
      "Training time : 11.74\n",
      " RandomForestClassifier - Accuracy: 0.87 (+/- 0.03)\n",
      "Training time : 9.28\n",
      " XGBClassifier - Accuracy: 0.89 (+/- 0.03)\n",
      "Training time : 6.06\n",
      "\n",
      "========= Noisy ( 7932 données ) =========\n",
      "\n",
      " LogisticRegression - Accuracy: 0.66 (+/- 0.03)\n",
      "Training time : 0.77\n",
      " ExtraTreesClassifier - Accuracy: 0.92 (+/- 0.02)\n",
      "Training time : 9.33\n",
      " GradientBoostingClassifier - Accuracy: 0.86 (+/- 0.02)\n",
      "Training time : 66.73\n",
      " HistGradientBoostingClassifier - Accuracy: 0.95 (+/- 0.01)\n",
      "Training time : 12.77\n",
      " RandomForestClassifier - Accuracy: 0.93 (+/- 0.02)\n",
      "Training time : 24.61\n",
      " XGBClassifier - Accuracy: 0.94 (+/- 0.01)\n",
      "Training time : 11.79\n",
      "\n",
      "========= Noisy ( 39660 données ) =========\n",
      "\n",
      " LogisticRegression - Accuracy: 0.66 (+/- 0.03)\n",
      "Training time : 4.17\n",
      " ExtraTreesClassifier - Accuracy: 0.99 (+/- 0.00)\n",
      "Training time : 34.92\n",
      " GradientBoostingClassifier - Accuracy: 0.87 (+/- 0.01)\n",
      "Training time : 353.6\n",
      " HistGradientBoostingClassifier - Accuracy: 0.99 (+/- 0.00)\n",
      "Training time : 16.76\n",
      " RandomForestClassifier - Accuracy: 1.00 (+/- 0.00)\n",
      "Training time : 130.77\n",
      " XGBClassifier - Accuracy: 1.00 (+/- 0.00)\n",
      "Training time : 52.2\n"
     ]
    }
   ],
   "source": [
    "for df in dataframes :\n",
    "    print(f\"\\n========= {df.name} ( {len(df)} données ) =========\\n\")\n",
    "    X = df.select_dtypes(include=['int', 'float'])\n",
    "    y = df[\"label\"]\n",
    "    \n",
    "    # transformation des labels car/truck en 0 et 1\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    target1 = unique[0]\n",
    "    target2 = unique[1]       \n",
    "    y.replace(to_replace=target1, value=0, inplace=True)\n",
    "    y.replace(to_replace=target2, value=1, inplace=True)    \n",
    "    \n",
    "    #mise à l'échelle logarithmique\n",
    "    X_log = log_normalization(X)\n",
    "    index_before_drop = X_log.index\n",
    "    X_log.dropna(inplace=True)\n",
    "    index_after_drop = X_log.index\n",
    "    dropped_index = set(index_before_drop) - set(index_after_drop)\n",
    "    y_log = y[~y.index.isin(dropped_index)]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=42)\n",
    "    for best_model in best_model_names :     \n",
    "        sc = launch_model(best_model, print_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435060cd",
   "metadata": {},
   "source": [
    " <a id=\"4\"></a>\n",
    " <div>\n",
    "    <h2 style=\"font-size:1.8em; color: #286fee;text-decoration:underline; letter-spacing:1px\">IV - Recherche et sélection des meilleures features </h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06b56b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r'../Data/data'\n",
    "df = pd.read_pickle(file)\n",
    "\n",
    "# répartition des features / labels dans les sets de test et de training\n",
    "X = df.select_dtypes(include=['int', 'float'])\n",
    "y = df[\"label\"]\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "target1 = unique[0]\n",
    "target2 = unique[1]\n",
    "# transformation des labels car/truck en 0 et 1\n",
    "y.replace(to_replace=target1, value=0, inplace=True)\n",
    "y.replace(to_replace=target2, value=1, inplace=True)    \n",
    "\n",
    "#mise à l'échelle logarithmique\n",
    "X_log = log_normalization(X)\n",
    "index_before_drop = X_log.index\n",
    "X_log.dropna(inplace=True)\n",
    "index_after_drop = X_log.index\n",
    "dropped_index = set(index_before_drop) - set(index_after_drop)\n",
    "y_log = y[~y.index.isin(dropped_index)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, test_size = 0.2, stratify=y_log, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "355c3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def search_features(model):\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    print(f\"\\n========= {model_name} =========\\n\")\n",
    "    \n",
    "    # Create a feature selector using Recursive Feature Elimination (RFE) with cross-validation\n",
    "    selector = RFECV(model, cv=StratifiedKFold(5), scoring='accuracy', verbose = 1)\n",
    "\n",
    "    # Fit the selector to the data\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "\n",
    "    # Get the selected features \n",
    "    selected_features = np.where(selector.get_support())[0] \n",
    "\n",
    "    # Plot the mean score vs the number of features\n",
    "    scores_df=pd.DataFrame({'mean':selector.cv_results_['mean_test_score']})\n",
    "    fig = px.line(scores_df, y='mean', x=scores_df.index + 1)\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': \"Visualisation des meilleures features\",\n",
    "            'font': {'size': 24},\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'\n",
    "        },\n",
    "        xaxis_title=\"features number\",\n",
    "        yaxis_title=\"accuracy\"    \n",
    "    )\n",
    "    fig.show()\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812dee6a",
   "metadata": {},
   "source": [
    "**Sélection des features pour le modèle Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae80a380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= RandomForestClassifier =========\n",
      "\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>mean=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71
         ],
         "xaxis": "x",
         "y": [
          0.547751290243303,
          0.7322376505283854,
          0.7821844023920701,
          0.8513967395756532,
          0.8533116244777588,
          0.8603690505447694,
          0.8770316212009502,
          0.8815085606619153,
          0.8795895797493241,
          0.8751085442778734,
          0.8911157532563283,
          0.8834234455640206,
          0.8821352502662405,
          0.8827742279020233,
          0.8789342180715982,
          0.8859834521176374,
          0.8834234455640206,
          0.8936696157942163,
          0.8981404112394529,
          0.8955885967068073,
          0.9013516834603097,
          0.8949455230605391,
          0.90839477349062,
          0.8962255263373475,
          0.8975075776193986,
          0.9000716801835014,
          0.8955947407225363,
          0.8968685999836159,
          0.8955885967068076,
          0.9000737281887442,
          0.8923855165069222,
          0.9007168018350127,
          0.8962214303268616,
          0.8994449905791759,
          0.8955885967068076,
          0.9007208978454985,
          0.8987957729171786,
          0.8962275743425903,
          0.8955947407225363,
          0.8962378143688048,
          0.8930306381584338,
          0.8994265585319898,
          0.8987937249119359,
          0.8994367985582044,
          0.8936716637994593,
          0.8962378143688049,
          0.8962234783321046,
          0.8936655197837308,
          0.8943085934299992,
          0.8930203981322192,
          0.8962357663635618,
          0.8911075612353567,
          0.8930347341689195,
          0.8904603915786022,
          0.8917424428606537,
          0.893661423773245,
          0.8955845006963219,
          0.8923814204964364,
          0.8878880969935283,
          0.8975157696403704,
          0.8994327025477187,
          0.893661423773245,
          0.8904603915786022,
          0.8879024330302286,
          0.890470631604817,
          0.8943085934299992,
          0.8891742442860654,
          0.8872675514049316,
          0.8936737118047023,
          0.892387564512165,
          0.8859834521176374
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 24
         },
         "text": "Visualisation des meilleures features",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "features number"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "accuracy"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"a71c4268-0946-4ce8-9fa1-aae5d6f9b919\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a71c4268-0946-4ce8-9fa1-aae5d6f9b919\")) {                    Plotly.newPlot(                        \"a71c4268-0946-4ce8-9fa1-aae5d6f9b919\",                        [{\"hovertemplate\":\"x=%{x}<br>mean=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71],\"xaxis\":\"x\",\"y\":[0.547751290243303,0.7322376505283854,0.7821844023920701,0.8513967395756532,0.8533116244777588,0.8603690505447694,0.8770316212009502,0.8815085606619153,0.8795895797493241,0.8751085442778734,0.8911157532563283,0.8834234455640206,0.8821352502662405,0.8827742279020233,0.8789342180715982,0.8859834521176374,0.8834234455640206,0.8936696157942163,0.8981404112394529,0.8955885967068073,0.9013516834603097,0.8949455230605391,0.90839477349062,0.8962255263373475,0.8975075776193986,0.9000716801835014,0.8955947407225363,0.8968685999836159,0.8955885967068076,0.9000737281887442,0.8923855165069222,0.9007168018350127,0.8962214303268616,0.8994449905791759,0.8955885967068076,0.9007208978454985,0.8987957729171786,0.8962275743425903,0.8955947407225363,0.8962378143688048,0.8930306381584338,0.8994265585319898,0.8987937249119359,0.8994367985582044,0.8936716637994593,0.8962378143688049,0.8962234783321046,0.8936655197837308,0.8943085934299992,0.8930203981322192,0.8962357663635618,0.8911075612353567,0.8930347341689195,0.8904603915786022,0.8917424428606537,0.893661423773245,0.8955845006963219,0.8923814204964364,0.8878880969935283,0.8975157696403704,0.8994327025477187,0.893661423773245,0.8904603915786022,0.8879024330302286,0.890470631604817,0.8943085934299992,0.8891742442860654,0.8872675514049316,0.8936737118047023,0.892387564512165,0.8859834521176374],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"features number\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"accuracy\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":24},\"text\":\"Visualisation des meilleures features\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a71c4268-0946-4ce8-9fa1-aae5d6f9b919');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  [ 0  1  4  5  8 15 17 18 23 24 26 27 32 35 38 40 42 43 49 53 55 58 64]\n"
     ]
    }
   ],
   "source": [
    "selected_features_rf = search_features(RandomForestClassifier())\n",
    "print(\"Selected features: \",selected_features_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e893ac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features :\n",
      " RandomForestClassifier - Accuracy: 0.888 (+/- 0.039)\n",
      "Selected features :\n",
      " RandomForestClassifier - Accuracy: 0.901 (+/- 0.032)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9013537314655526"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All features :\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "launch_model(RandomForestClassifier(), n_commas = 3)\n",
    "print(\"Selected features :\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log.iloc[:,selected_features_rf], y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "launch_model(RandomForestClassifier(), n_commas = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16938e5a",
   "metadata": {},
   "source": [
    "**Sélection des features pour le modèle XgBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68ca0493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= XGBClassifier =========\n",
      "\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>mean=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23
         ],
         "xaxis": "x",
         "y": [
          0.5951318915376423,
          0.6585483738838371,
          0.7386335709019416,
          0.8026849348734333,
          0.8206295568116655,
          0.837298271483575,
          0.8475608257557139,
          0.8571598263291555,
          0.8738121569591218,
          0.8757208978454984,
          0.8859793561071516,
          0.8866080937167199,
          0.8904644875890881,
          0.8994306545424756,
          0.9071147702138118,
          0.9019886130908494,
          0.9019947571065782,
          0.8904644875890881,
          0.905189645285492,
          0.9039157860244122,
          0.906475792578029,
          0.9039157860244122,
          0.8930122061112475
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 24
         },
         "text": "Visualisation des meilleures features",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "features number"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "accuracy"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"7133217f-6a0d-44e2-8f2b-c47f53ed2413\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7133217f-6a0d-44e2-8f2b-c47f53ed2413\")) {                    Plotly.newPlot(                        \"7133217f-6a0d-44e2-8f2b-c47f53ed2413\",                        [{\"hovertemplate\":\"x=%{x}<br>mean=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],\"xaxis\":\"x\",\"y\":[0.5951318915376423,0.6585483738838371,0.7386335709019416,0.8026849348734333,0.8206295568116655,0.837298271483575,0.8475608257557139,0.8571598263291555,0.8738121569591218,0.8757208978454984,0.8859793561071516,0.8866080937167199,0.8904644875890881,0.8994306545424756,0.9071147702138118,0.9019886130908494,0.9019947571065782,0.8904644875890881,0.905189645285492,0.9039157860244122,0.906475792578029,0.9039157860244122,0.8930122061112475],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"features number\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"accuracy\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":24},\"text\":\"Visualisation des meilleures features\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7133217f-6a0d-44e2-8f2b-c47f53ed2413');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  [ 0  5  6  7  8  9 10 11 12 15 18 19 20 21 22]\n"
     ]
    }
   ],
   "source": [
    "selected_features_xgb = search_features(xgb.XGBClassifier(objective='binary:logistic'))\n",
    "print(\"Selected features: \",selected_features_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9494744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features :\n",
      " XGBClassifier - Accuracy: 0.896 (+/- 0.027)\n",
      "Selected features :\n",
      " XGBClassifier - Accuracy: 0.762 (+/- 0.031)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7616859179159499"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All features :\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "launch_model(xgb.XGBClassifier(objective='binary:logistic'), n_commas = 3)\n",
    "print(\"Selected features :\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log.iloc[:,selected_features_xgb], y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "launch_model(xgb.XGBClassifier(objective='binary:logistic'), n_commas = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc3451",
   "metadata": {},
   "source": [
    "**Sélection des features pour le modèle ExtraTreesClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72fc225f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= ExtraTreesClassifier =========\n",
      "\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>mean=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15
         ],
         "xaxis": "x",
         "y": [
          0.5381461456541329,
          0.650882690259687,
          0.7270848693372656,
          0.7616941099369214,
          0.7988531170639797,
          0.7924449086589662,
          0.7783402965511591,
          0.7930838862947489,
          0.7796346358646679,
          0.7853915786024412,
          0.7777115589415908,
          0.7821925944130416,
          0.7796202998279675,
          0.7796325878594248,
          0.7655382157778323
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 24
         },
         "text": "Visualisation des meilleures features",
         "x": 0.5,
         "xanchor": "center",
         "yanchor": "top"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "features number"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "accuracy"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"28ea71f8-38e7-4095-bdc0-7b4fde19a7ed\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"28ea71f8-38e7-4095-bdc0-7b4fde19a7ed\")) {                    Plotly.newPlot(                        \"28ea71f8-38e7-4095-bdc0-7b4fde19a7ed\",                        [{\"hovertemplate\":\"x=%{x}<br>mean=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"xaxis\":\"x\",\"y\":[0.5381461456541329,0.650882690259687,0.7270848693372656,0.7616941099369214,0.7988531170639797,0.7924449086589662,0.7783402965511591,0.7930838862947489,0.7796346358646679,0.7853915786024412,0.7777115589415908,0.7821925944130416,0.7796202998279675,0.7796325878594248,0.7655382157778323],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"features number\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"accuracy\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":24},\"text\":\"Visualisation des meilleures features\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('28ea71f8-38e7-4095-bdc0-7b4fde19a7ed');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  [ 0  9 10 13 14]\n"
     ]
    }
   ],
   "source": [
    "selected_features_et = search_features(ExtraTreesClassifier())\n",
    "print(\"Selected features: \",selected_features_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17908f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features :\n",
      " ExtraTreesClassifier - Accuracy: 0.896 (+/- 0.035)\n",
      "Selected features :\n",
      " ExtraTreesClassifier - Accuracy: 0.630 (+/- 0.063)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6303309576472516"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All features :\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "launch_model(ExtraTreesClassifier(), n_commas = 3)\n",
    "print(\"Selected features :\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_log.iloc[:,selected_features_et], y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "launch_model(ExtraTreesClassifier(), n_commas = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0044703",
   "metadata": {},
   "source": [
    " <a id=\"5\"></a>\n",
    " <div>\n",
    "    <h2 style=\"font-size:1.8em; color: #286fee;text-decoration:underline; letter-spacing:1px\">V - Hyperparamétrage </h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce51b0",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5455c0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.15, 'max_depth': 8, 'n_estimators': 100, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1.0}\n",
      "Accuracy: 90.46% (+/- 0.65%)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "# Define the parameter grid for the ExtraTreesClassifier model\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 120],\n",
    "    'max_depth': [8,10],\n",
    "    'learning_rate': [0.15, 0.2],\n",
    "    'subsample': [ 1.0],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'gamma': [0, 0.1],\n",
    "    'reg_lambda': [1, 1.5],\n",
    "    'scale_pos_weight': [1, 1.5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_xgb_params = grid.best_params_\n",
    "best_xgb_model = grid.best_estimator_\n",
    "print(best_xgb_params)\n",
    "\n",
    "# Use the best parameters to train the XGBoost model on the full training set\n",
    "best_xgb_model = xgb.XGBClassifier(objective='binary:logistic',**best_xgb_params)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the best XGBoost model using cross-validation\n",
    "accuracies = cross_val_score(best_xgb_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Print the average accuracy and the standard deviation of the accuracy\n",
    "print('Accuracy: {:.2f}% (+/- {:.2f}%)'.format(accuracies.mean() * 100, accuracies.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495575d6",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5e40b6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 25, 'max_features': 'log2', 'min_samples_split': 8, 'n_estimators': 90}\n",
      "Accuracy: 89.62% (+/- 1.76%)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_log.iloc[:,selected_features_rf], y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [90, 100, 110],\n",
    "    'max_depth': [25,30],\n",
    "    'min_samples_split': [8, 9, 10],\n",
    "     'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_rf_params = grid.best_params_\n",
    "best_rf_model = grid.best_estimator_\n",
    "print(best_rf_params)\n",
    "\n",
    "# Use the best parameters to train the XGBoost model on the full training set\n",
    "best_rf_model = RandomForestClassifier(**best_rf_params)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "#export the model\n",
    "dump(best_rf_model, '../models/best_rf_model.pkl')\n",
    "\n",
    "# Evaluate the accuracy of the best XGBoost model using cross-validation\n",
    "accuracies = cross_val_score(best_rf_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Print the average accuracy and the standard deviation of the accuracy\n",
    "print('Accuracy: {:.2f}% (+/- {:.2f}%)'.format(accuracies.mean() * 100, accuracies.std() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e379647",
   "metadata": {},
   "source": [
    "**Extra Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9788b2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_split': 3, 'n_estimators': 300}\n",
      "Accuracy: 91.03% (+/- 2.15%)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, test_size = 0.2, stratify=y_log, random_state=42)\n",
    "\n",
    "etc_model = ExtraTreesClassifier()\n",
    "\n",
    "# Define the parameter grid for the ExtraTreesClassifier model\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 200, 300, 500],\n",
    "    'max_depth': [None, 2],\n",
    "    'min_samples_split': [ 3],\n",
    "    'max_features': [ None],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(etc_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_etc_params = grid.best_params_\n",
    "best_etc_model = grid.best_estimator_\n",
    "print(best_etc_params)\n",
    "\n",
    "# Use the best parameters to train the XGBoost model on the full training set\n",
    "best_etc_model = ExtraTreesClassifier(**best_etc_params)\n",
    "best_etc_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the best XGBoost model using cross-validation\n",
    "accuracies = cross_val_score(best_etc_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Print the average accuracy and the standard deviation of the accuracy\n",
    "print('Accuracy: {:.2f}% (+/- {:.2f}%)'.format(accuracies.mean() * 100, accuracies.std() * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "30395d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/best_etc_model.pkl']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export the models\n",
    "dump(best_xgb_model, '../models/best_xgb_model.pkl')\n",
    "dump(best_rf_model, '../models/best_rf_model.pkl')\n",
    "dump(best_etc_model, '../models/best_etc_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7056d69",
   "metadata": {},
   "source": [
    " <a id=\"6\"></a>\n",
    " <div>\n",
    "    <h2 style=\"font-size:1.8em; color: #286fee;text-decoration:underline; letter-spacing:1px\">VI - Ensemble Learning </h2>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "effd65cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier 0.8849104859335039\n",
      "RandomForestClassifier 0.8823529411764706\n",
      "ExtraTreesClassifier 0.9130434782608695\n",
      "StackingClassifier 0.9002557544757033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "model_1 = xgb.XGBClassifier(objective='binary:logistic',**best_xgb_params)\n",
    "model_2 = RandomForestClassifier()\n",
    "model_3 = ExtraTreesClassifier(**best_etc_params)\n",
    "model_4 = StackingClassifier([('XGB', model_1),  ('ETC', model_3)], final_estimator = LogisticRegression())\n",
    "\n",
    "for model in (model_1, model_2, model_3, model_4):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.__class__.__name__, model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f7c5a24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Define base estimator\n",
    "base_estimator = xgb.XGBClassifier(objective='binary:logistic',**best_xgb_params)\n",
    "\n",
    "# Define BaggingClassifier with base estimator and number of estimators\n",
    "bagging = BaggingClassifier(base_estimator=base_estimator, n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit bagging on training data\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate accuracy on test data\n",
    "accuracy = bagging.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd90c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model_1 = RandomForestClassifier()\n",
    "model_2 = xgb.XGBClassifier(objective='binary:logistic', **best_xgb_params)\n",
    "model_3 = ExtraTreesClassifier(**best_etc_params)\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('rf', model_1),\n",
    "    ('xgboost', model_2),\n",
    "    ('etc', model_3)], voting='hard')\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on test set: {:.3f}\".format(ensemble.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
